{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN49eRpNdXmXRbBEq9dlxLs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Anomaly Detection with color dataset\n","* CIFAR10 데이터셋을 활용해 이상탐지를 진행해봅시다.\n","* import 패키지와 디바이스 세팅을 설정합니다."],"metadata":{"id":"uSEuGvuqeUPb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8PavpS6YY6ZV"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n","from torchvision import datasets, transforms\n","import numpy as np\n","\n","# Device 설정: CUDA 사용\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n"]},{"cell_type":"markdown","source":["### CIFAR 10 Class 정리하기\n","\n","* 기본 클래스 Labels\n","```\n","0: airplane, 1: automobile, 2: bird,\n","3: cat, 4: deer, 5: dog,\n","6: frog, 7: horse, 8: ship, 9: truck\n","```\n"],"metadata":{"id":"xcMheOY3osIu"}},{"cell_type":"code","source":["# 사용자 정의 데이터셋: CIFAR10에서 원하는 클래스만 필터링하고 라벨 재정의\n","# 선택할 클래스: 고양이(3), 사슴(4), 개(5), 말(7)\n","# ‘이상’(1)으로 취급할 CIFAR‑10 원본 라벨\n","selected_classes = [3, 4, 5, 7]     # 고양이, 사슴, 개, 말\n","\n","class CIFAR10Subset(Dataset):\n","    \"\"\"\n","    CIFAR‑10 전체를 사용하되\n","      - selected_classes  →  1\n","      - 나머지            →  0\n","    으로 라벨을 재정의한 데이터셋\n","    \"\"\"\n","    def __init__(self, root, train=True, transform=None, download=False):\n","        self.dataset  = datasets.CIFAR10(root=root,\n","                                         train=train,\n","                                         transform=transform,\n","                                         download=download)\n","        self.transform = transform\n","\n","        # 원본 라벨을 이진 라벨로 매핑\n","        self.labels = [\n","            1.0 if target in selected_classes else 0.0\n","            for _, target in self.dataset\n","        ]\n","        \"\"\" 람다식 >> 반복문\n","        # 결과를 저장할 빈 리스트를 먼저 생성합니다.\n","        labels_list = []\n","\n","        # self.dataset을 순회하는 반복문을 시작합니다.\n","        for _, target in self.dataset:\n","            # target이 selected_classes에 있는지 확인합니다.\n","            if target in selected_classes:\n","                # 조건이 참이면 1.0을 리스트에 추가합니다.\n","                labels_list.append(1.0)\n","            else:\n","                # 조건이 거짓이면 0.0을 리스트에 추가합니다.\n","                labels_list.append(0.0)\n","\n","        # 완성된 리스트를 self.labels에 할당합니다.\n","        self.labels = labels_list\n","        \"\"\"\n","\n","    def __len__(self):\n","        # CIFAR‑10 전체 샘플 수 그대로\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        image, _ = self.dataset[idx]                    # 원본 라벨은 버림\n","        label = torch.tensor(self.labels[idx],      # float32 Target\n","                             dtype=torch.float32)\n","        return image, label\n"],"metadata":{"id":"qV3ureCHZlGd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### CIFAR 10 데이터셋 활용하기\n","* 이상 데이터 설정 후 데이터셋 정리하기"],"metadata":{"id":"amy_tNx1pEse"}},{"cell_type":"code","source":["# 이미지 전처리: CIFAR10은 32x32 이미지이므로 ToTensor()와 정규화만 적용\n","transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","# 학습/테스트 데이터셋 준비\n","train_dataset = CIFAR10Subset(root='./data', train=True, transform=transform, download=True)\n","test_dataset = CIFAR10Subset(root='./data', train=False, transform=transform, download=True)\n"],"metadata":{"id":"Z6L1Cf8dpBU5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = #TODO\n","train_loader = DataLoader(#TODO, batch_size=#TODO, shuffle=#TODO)\n","test_loader = DataLoader(#TODO, batch_size=#TODO, shuffle=False)"],"metadata":{"id":"JgTgd0yS4f98"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.bincount(train_targets)"],"metadata":{"id":"GGG-VMyn5PZC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### CNN 모델 구성하기\n","* CNN 모델 분류기 구현"],"metadata":{"id":"tTBl4p9-phj7"}},{"cell_type":"code","source":["# VGG 스타일의 CNN 네트워크 (입력: 32x32x3)\n","class VGGLikeCNN(nn.Module):\n","    def __init__(self):\n","        super(VGGLikeCNN, self).__init__()\n","        self.conv_model = nn.Sequential( #3 32 32\n","            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1), # 16 32 32\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2), # 16, 16, 16\n","\n","            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1), # 32 16 16\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2), # 32, 8, 8\n","        )\n","        self.classifier = nn.Sequential(\n","           nn.Linear(32 * 8 * 8, 64),\n","           nn.ReLU(),\n","           nn.Linear(64, 1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv_model(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","\n","        return x\n","\n","model = VGGLikeCNN().to(device)\n","print(model)\n"],"metadata":{"id":"9_4NbAJdZlJb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","#nn.BCEWithLogitsLoss\n","\"\"\"\n","양성 클래스에 적용할 가중치를 계산합니다.\n","\n","class_counts[0]: 음성 클래스(label=0)의 샘플 개수입니다.\n","class_counts[1]: 양성 클래스(label=1)의 샘플 개수입니다.\n","\n","계산식: pos_weight는 (음성 클래스 개수) / (양성 클래스 개수) 로 계산됩니다.\n","예시: 만약 음성(0) 샘플이 900개이고 양성(1) 샘플이 100개라면, pos_weight는 900 / 100 = 9가 됩니다.\n","\n","즉, 양성 클래스가 음성 클래스보다 9배 적다는 의미이며, 이 값을 가중치로 사용합니다.\n","\"\"\"\n","pos_weight = (class_counts[0] / class_counts[1]).float().to(device)\n","\n","\n","\"\"\"\n","계산된 pos_weight는 BCEWithLogitsLoss 함수의 인자로 전달되어 손실 함수(criterion)를 생성합니다.\n","\n","BCEWithLogitsLoss: 이진 분류를 위한 손실 함수로,\n","모델의 출력(Logits)에 시그모이드(Sigmoid) 함수를 내부적으로 적용한 후\n","이진 교차 엔트로피(Binary Cross Entropy) 손실을 계산합니다.\n","\n","pos_weight 역할: 이 인자는 손실을 계산할 때 오직 양성 클래스(label=1)에 대한 손실 값에만 곱해집니다.\n","위 예시처럼 pos_weight가 9라면, 모델이 양성 샘플을 잘못 예측했을 때 발생하는 손실이 9배로 증폭됩니다.\n","\n","음성 클래스에 대한 손실은 그대로 유지됩니다.\n","\"\"\"\n","criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)"],"metadata":{"id":"hVQhSGRm72TT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pos_weight"],"metadata":{"id":"xg9bpT1d8taW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 학습 및 검증"],"metadata":{"id":"GxRWC_v4rtCu"}},{"cell_type":"code","source":["num_epochs = 10\n","best_val_loss = float('inf')\n","\n","patience = 5\n","patience_counter = 0\n","\n","for epoch in range(1, num_epochs+1):\n","    model.train()\n","    running_loss = 0.0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device).unsqueeze(1)  # shape: (batch_size, 1)\n","\n","        optimizer.zero_grad()\n","        outputs = #TODO\n","        loss = #TODO\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * images.size(0)\n","\n","    train_loss = running_loss / len(train_loader.dataset)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in test_loader:\n","            images = images.to(device)\n","            labels = labels.to(device).unsqueeze(1)\n","            outputs = #TODO\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * images.size(0)\n","\n","            preds = torch.sigmoid(outputs) >= 0.5\n","            correct += (preds.float() == labels).sum().item()\n","            total += labels.size(0)\n","    val_loss = val_loss / len(test_loader.dataset)\n","    val_acc = correct / total\n","\n","    print(f\"Epoch [{epoch}/{num_epochs}] Train Loss: {train_loss:.4f}  Val Loss: {val_loss:.4f}  Val Acc: {val_acc:.4f}\")\n","\n","    # Early stopping\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        patience_counter = 0\n","        best_model_state = model.state_dict()\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= patience:\n","            print(\"Early stopping triggered.\")\n","            break\n","\n"],"metadata":{"id":"sZJfX8gWZlMi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트 평가 (최적 모델 로드)\n","model.load_state_dict(best_model_state)\n","model.eval()\n","test_loss = 0.0\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device).unsqueeze(1)\n","\n","        outputs = #TODO\n","        loss = #TODO\n","        test_loss += loss.item() * images.size(0)\n","\n","        preds = torch.sigmoid(outputs) >= 0.5\n","        correct += (preds.float() == labels).sum().item()\n","        total += labels.size(0)\n","test_loss = test_loss / len(test_loader.dataset)\n","test_acc = correct / total\n","print(f\"Test Loss: {test_loss:.4f}  Test Accuracy: {test_acc:.4f}\")"],"metadata":{"id":"yqBKd9V1gHjd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 학습 결과 확인"],"metadata":{"id":"wrdHT2UprvzX"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def unnormalize(image, mean, std):\n","    image = image.cpu().clone()\n","    # image = image * torch.tensor(std).view(3,1,1) + torch.tensor(mean).view(3,1,1)\n","    image = image.numpy().transpose(1,2,0)\n","    image = np.clip(image, 0, 1)\n","    return image\n","\n","def test_model_on_examples(model, loader, device, num_examples=10):\n","    \"\"\"\n","    주어진 DataLoader에서 몇 개의 이미지를 샘플링하여 모델의 예측 결과를 출력합니다.\n","    정답(예측이 실제와 일치)인 경우 제목은 파란색, 오답은 빨간색으로 표시합니다.\n","    \"\"\"\n","    model.eval()\n","    examples = 0\n","    # transforms.Normalize에 사용된 값\n","    mean = [0.4914, 0.4822, 0.4465]\n","    std = [0.247, 0.243, 0.261]\n","\n","    with torch.no_grad():\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            # BCEWithLogitsLoss 사용 시 sigmoid 후 threshold 0.5로 예측\n","            preds = (torch.sigmoid(outputs) >= 0.5).float()\n","            for i in range(len(images)):\n","                if examples >= num_examples:\n","                    return\n","                example_image = unnormalize(images[i], mean, std)\n","                true_label = int(labels[i].item())\n","                predicted_label = int(preds[i].item())\n","                # 정답이면 파란색, 오답이면 빨간색\n","                title_color = 'blue' if true_label == predicted_label else 'red'\n","\n","                plt.figure(figsize=(2,2))\n","                plt.imshow(example_image)\n","                plt.title(f\"True: {true_label}, Predicted: {predicted_label}\", color=title_color)\n","                plt.axis(\"off\")\n","                plt.show()\n","                examples += 1\n","\n","# 테스트 데이터에서 예제 10개 시각화\n","test_model_on_examples(model, test_loader, device, num_examples=10)\n"],"metadata":{"id":"VKOi0V2cZlWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torchmetrics"],"metadata":{"id":"sLMXPGSmZnoa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ─── 시각적 평가 추가 (sklearn + matplotlib) ─────────────────────────────\n","\n","from sklearn.metrics import (\n","    roc_auc_score,\n","    precision_score,\n","    recall_score,\n","    f1_score,\n","    confusion_matrix,\n","    roc_curve,\n","    precision_recall_curve\n",")\n","import matplotlib.pyplot as plt\n","\n","# 1) 테스트셋 전체 순회하며 예측값·확률·실제 라벨 수집\n","all_labels = []\n","all_probs  = []\n","all_preds  = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        logits = model(images)\n","        probs  = torch.sigmoid(logits).view(-1).cpu().numpy()\n","        preds  = (probs >= 0.5).astype(int)\n","\n","        all_probs.extend(probs.tolist())\n","        all_preds.extend(preds.tolist())\n","        all_labels.extend(labels.cpu().numpy().astype(int).tolist())\n","\n","# 2) 주요 지표 계산 및 출력\n","roc_auc   = roc_auc_score(all_labels, all_probs)\n","precision = precision_score(all_labels, all_preds, zero_division=0)\n","recall    = recall_score(all_labels, all_preds, zero_division=0)\n","f1        = f1_score(all_labels, all_preds, zero_division=0)\n","cm        = confusion_matrix(all_labels, all_preds)\n","\n","print(\"===== Evaluation Metrics =====\")\n","print(f\"ROC-AUC Score : {roc_auc:.4f}\")\n","print(f\"Precision     : {precision:.4f}\")\n","print(f\"Recall        : {recall:.4f}\")\n","print(f\"F1 Score      : {f1:.4f}\")\n","print(\"\\nConfusion Matrix:\")\n","print(cm)\n","\n","# 3) ROC Curve\n","fpr, tpr, _ = roc_curve(all_labels, all_probs)\n","plt.figure()\n","plt.plot(fpr, tpr)\n","plt.plot([0, 1], [0, 1], linestyle='--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve')\n","plt.show()\n","\n","# 4) Precision-Recall Curve\n","precision_vals, recall_vals, _ = precision_recall_curve(all_labels, all_probs)\n","plt.figure()\n","plt.plot(recall_vals, precision_vals)\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall Curve')\n","plt.show()\n","\n","# 5) Confusion Matrix Heatmap\n","plt.figure()\n","plt.imshow(cm, interpolation='nearest')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.colorbar()\n","plt.show()\n","\n","# 6) 주요 지표 바 차트\n","metrics = {'ROC-AUC': roc_auc, 'Precision': precision, 'Recall': recall, 'F1': f1}\n","plt.figure()\n","plt.bar(list(metrics.keys()), list(metrics.values()))\n","plt.ylim(0, 1)\n","plt.title('Evaluation Metrics')\n","plt.ylabel('Score')\n","plt.show()\n"],"metadata":{"id":"JBGGxrOrTmKA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LFDdzotGYffX"},"execution_count":null,"outputs":[]}]}