{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"H3JFIM50dgst"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vv3PVFpmUPw1"},"outputs":[],"source":["# ==================================================\n","# 0. 의존성\n","# ==================================================\n","import torch, numpy as np, torch.nn as nn\n","import torch.autograd as autograd\n","from torch.nn.utils import spectral_norm\n","from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, DataLoader, Subset, random_split, ConcatDataset\n","from sklearn.metrics import roc_auc_score, average_precision_score\n","import matplotlib.pyplot as plt\n","import os\n","from glob import glob\n","from PIL import Image\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","IMG_SIZE     = 256                  # 이미지 크기\n","IN_CHANNELS  = 3                    # 입력 채널 (RGB)\n","ANOMALY_LABEL = 1\n","LATENT_DIM   = #TODO\n","BATCH, EPOCHS, TH_PCT = 16, #TODO, 95\n","LR_G, LR_D = #TODO, #TODO               # G 더 빠르게\n","lambda_gp, lambda_con, lambda_lat = 0, 5, 5\n","ALPHA = 0.9                      # score 가중치\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdV7d_RYU-c3"},"outputs":[],"source":["# ==================================================\n","# 1. 데이터 셋업 (train / val / test)\n","# ==================================================\n","ROOT_DIR = '/content/drive/MyDrive/Data/MVTecAD/'\n","\n","class MVTecADMulti(Dataset):\n","    def __init__(self, root_dir:str, phase:str='train'):\n","        assert phase in ('train', 'test')\n","        self.phase = phase\n","        self.paths = []\n","        cat_path = os.path.join(root_dir, 'bottle')\n","\n","        if not os.path.isdir(cat_path):\n","            raise FileNotFoundError(f\"지정된 경로에 'bottle' 폴더가 없습니다: {cat_path}\")\n","\n","        if phase == 'train':\n","            train_path = os.path.join(cat_path, 'train', 'good', '*.png')\n","            self.paths += [(p, 0) for p in glob(train_path)] # 정상: 0\n","        else:\n","            test_good_path = os.path.join(cat_path, 'test', 'good', '*.png')\n","            self.paths += [(p, 0) for p in glob(test_good_path)] # 정상: 0\n","            test_dir = os.path.join(cat_path, 'test')\n","            for defect in os.listdir(test_dir):\n","                if defect == 'good': continue\n","                defect_dir = os.path.join(test_dir, defect)\n","                if os.path.isdir(defect_dir):\n","                    defect_path = os.path.join(defect_dir, '*.png')\n","                    self.paths += [(p, 1) for p in glob(defect_path)] # 이상: 1\n","\n","        self.tf = transforms.Compose([\n","            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.5] * 3, [0.5] * 3) # [0,1] -> [-1,1]\n","        ])\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.paths[idx]\n","        img = Image.open(img_path).convert('RGB')\n","        img_tensor = self.tf(img)\n","        return img_tensor, label, img_path\n"]},{"cell_type":"code","source":["# --- 데이터셋 및 데이터로더 생성 ---\n","normal_ds = MVTecADMulti(ROOT_DIR, phase='train')\n","n_train = int(0.9 * len(normal_ds))\n","train_ds, val_ds = random_split(\n","    normal_ds, [n_train, len(normal_ds) - n_train],\n","    generator=torch.Generator().manual_seed(42)\n",")\n","test_ds = MVTecADMulti(ROOT_DIR, phase='test')\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=2, pin_memory=True)\n","val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)\n","test_loader  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)\n","\n","print(\"데이터셋 설정 완료!\")\n","print(f\"Train: {len(train_ds)}, Validation: {len(val_ds)}, Test: {len(test_ds)}\")\n"],"metadata":{"id":"9hJx2NH6dG55"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_MMV5IfZVA9d"},"outputs":[],"source":["# ==================================================\n","# 2. 네트워크 (GANomaly)\n","# ==================================================\n","#TODO\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q0FgNmlTVExr"},"outputs":[],"source":["# ==================================================\n","# 3. 학습 루프 (WGAN-GP + ℓ_con + ℓ_lat)\n","# ==================================================\n","opt_G = torch.optim.Adam(G.parameters(), LR_G, betas=(0.5, 0.999))\n","opt_D = torch.optim.Adam(D.parameters(), LR_D, betas=(0.5, 0.999))\n","\n","def gradient_penalty(x_real, x_fake):\n","    alpha = torch.rand(x_real.size(0), 1, 1, 1, device=DEVICE)\n","    interpolated = (alpha * x_real + (1 - alpha) * x_fake).requires_grad_(True)\n","    d_interpolated = D(interpolated)\n","    grad = autograd.grad(\n","        outputs=d_interpolated, inputs=interpolated,\n","        grad_outputs=torch.ones_like(d_interpolated),\n","        create_graph=True, retain_graph=True\n","    )[0]\n","    grad_flat = grad.view(grad.size(0), -1)\n","    gp = ((grad_flat.norm(2, dim=1) - 1) ** 2).mean()\n","    return gp\n","\n","for ep in range(1, EPOCHS + 1):\n","    G.train(); D.train()\n","    g_sum = d_sum = 0.\n","    n_critic = 5\n","\n","    for i, (x, _, _) in enumerate(train_loader):\n","        x = x.to(DEVICE)\n","        # ----- 판별자(D) 학습 -----\n","        with torch.no_grad():\n","            x_fake, _, _ = G(x)\n","\n","        d_real = D(x).mean()\n","        d_fake = D(x_fake).mean()\n","        gp = gradient_penalty(x.detach(), x_fake.detach())\n","        loss_D = d_fake - d_real + lambda_gp * gp\n","\n","        opt_D.zero_grad()\n","        loss_D.backward()\n","        opt_D.step()\n","\n","        d_sum += loss_D.item() * x.size(0)\n","\n","        # ----- 생성자(G) 학습 -----\n","        if (i + 1) % n_critic == 0:\n","            x_fake, z, z_hat = G(x)\n","\n","            adv_loss = -D(x_fake).mean()\n","            con_loss = nn.functional.l1_loss(x, x_fake) # L1이 L2보다 시각적으로 나은 경우 많음\n","            lat_loss = nn.functional.mse_loss(z, z_hat)\n","\n","            loss_G = adv_loss + lambda_con * con_loss + lambda_lat * lat_loss\n","\n","            opt_G.zero_grad()\n","            loss_G.backward()\n","            opt_G.step()\n","            g_sum += loss_G.item() * x.size(0)\n","\n","    print(f\"[{ep:02d}/{EPOCHS}] | L_G: {g_sum/(len(train_ds)/n_critic):.4f} | L_D: {d_sum/len(train_ds):.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g6a2A7UyVFb0"},"outputs":[],"source":["# ==================================================\n","# 4. 임계치 계산 (train+val 정상 90-percentile)\n","# ==================================================\n","def anomaly_score(x):\n","    G.eval()\n","    with torch.no_grad():\n","        x_hat, z, z_hat = G(x)\n","        con_loss = torch.mean(torch.abs(x - x_hat), dim=(1, 2, 3))\n","        lat_loss = torch.mean((z - z_hat)**2, dim=1)\n","    return ALPHA * con_loss + (1 - ALPHA) * lat_loss, x_hat\n","\n","# --- val 데이터(정상)로 스코어 계산 ---\n","scores_val = []\n","with torch.no_grad():\n","    for x, _, _ in val_loader:\n","        x = x.to(DEVICE)\n","        sc, _ = anomaly_score(x)\n","        scores_val.extend(sc.cpu().numpy())\n","\n","THRESH = np.percentile(scores_val, TH_PCT)\n","print(f\"\\n[Threshold] {TH_PCT}-percentile = {THRESH:.6f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Ky9hwLaVJ_r"},"outputs":[],"source":["# ==================================================\n","# 5. 테스트 평가\n","# ==================================================\n","y_true, y_score = [], []\n","recon_store = []\n","G.eval()\n","with torch.no_grad():\n","    for x, y, _ in test_loader:\n","        x  = x.to(DEVICE)\n","        sc, xh = anomaly_score(x)\n","        y_score.extend(sc.cpu().numpy())\n","        y_true.extend(y.numpy()) # y는 이미 0 또는 1\n","        recon_store.append(((x.cpu(), xh.cpu(), y.cpu())))\n","\n","auc = roc_auc_score(y_true, y_score)\n","ap = average_precision_score(y_true, y_score)\n","print(f\"[Test] AUROC: {auc:.4f} | AUPRC: {ap:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MxyBELkjWeW3"},"outputs":[],"source":["# ==================================================\n","# 6. 시각화\n","# ==================================================\n","# 6-1. 입력 ↔ 재구성 이미지 비교\n","norm_pairs, anom_pairs = [], []\n","for x_batch, xh_batch, y_batch in recon_store:\n","    for img, rec, label in zip(x_batch, xh_batch, y_batch):\n","        pair = (img.add(1).div(2), rec.add(1).div(2)) # [-1,1] -> [0,1]\n","        if label.item() == ANOMALY_LABEL and len(anom_pairs) < 5:\n","            anom_pairs.append(pair)\n","        elif label.item() == 0 and len(norm_pairs) < 5:\n","            norm_pairs.append(pair)\n","    if len(norm_pairs) >= 5 and len(anom_pairs) >= 5:\n","        break\n","\n","fig, axes = plt.subplots(2, 10, figsize=(20, 4.5))\n","plt.suptitle(\"GANomaly Reconstruction — Normal vs. Anomaly\", y=1.02, fontsize=16)\n","\n","# Plot Normal Images\n","for col, (inp, rec) in enumerate(norm_pairs):\n","    axes[0, col].imshow(inp.permute(1, 2, 0))\n","    axes[0, col].axis(\"off\")\n","    axes[1, col].imshow(rec.permute(1, 2, 0))\n","    axes[1, col].axis(\"off\")\n","\n","# Plot Anomaly Images\n","for col, (inp, rec) in enumerate(anom_pairs):\n","    i = col + 5\n","    axes[0, i].imshow(inp.permute(1, 2, 0))\n","    axes[0, i].axis(\"off\")\n","    axes[1, i].imshow(rec.permute(1, 2, 0))\n","    axes[1, i].axis(\"off\")\n","\n","axes[0, 0].set_ylabel(\"Input\", fontsize=12)\n","axes[1, 0].set_ylabel(\"Recon\", fontsize=12)\n","axes[0, 2].set_title(\"Normal\", fontsize=14)\n","axes[0, 7].set_title(\"Anomaly\", fontsize=14)\n","plt.tight_layout()\n","plt.show()\n","\n","# 6-2. 이상치 점수 분포 히스토그램\n","y_true = np.array(y_true)\n","y_score = np.array(y_score)\n","scores_norm = y_score[y_true == 0]\n","scores_anom = y_score[y_true == 1]\n","\n","plt.figure(figsize=(8, 5))\n","plt.hist(scores_norm, bins=50, alpha=0.7, label='Normal', color='blue', density=True)\n","plt.hist(scores_anom, bins=50, alpha=0.7, label='Anomaly', color='red', density=True)\n","plt.axvline(THRESH, linestyle=\"--\", color=\"k\", label=f\"Threshold ({TH_PCT}%) = {THRESH:.4f}\")\n","\n","plt.title(\"Anomaly Score Distribution (Test Set)\")\n","plt.xlabel(\"Anomaly Score\")\n","plt.ylabel(\"Density\")\n","plt.legend()\n","plt.grid(axis='y', alpha=0.5)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_j5H8n5WerH"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMZkNXGRTZh3z9pBsujBn1l"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}