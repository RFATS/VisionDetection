{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HyCiqD8RZbEO"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G47eftO7-h8n"},"outputs":[],"source":["ROOT_DIR  = '/content/drive/MyDrive/Data/MVTecAD'  # ë°ì´í„°ì…‹ ìƒìœ„ ê²½ë¡œ\n","SAVE_NAME = f'best_skipgan.pt'\n","\n","# =============================================================\n","# 0.  ì˜ì¡´ì„± & ì „ì—­ ì„¤ì •\n","# =============================================================\n","import os, random, time\n","from glob   import glob\n","from pathlib import Path\n","import numpy as np, matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","import copy\n","\n","import torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as T\n","from sklearn.metrics import roc_auc_score\n","from torch.nn.utils import spectral_norm\n","import torch.autograd as autograd\n","\n","IMG_SIZE   = 256\n","BATCH_SIZE = 16\n","EPOCHS     = #TODO\n","LR_G, LR_D = #TODO\n","BETAS = (0.5, 0.999)\n","lambda_GP = 0.0 #spectral norm\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('âœ… device:', DEVICE)\n","\n","# =============================================================\n","# 1.  ë°ì´í„°ì…‹ & DataLoader\n","# =============================================================\n","class MVTecADMulti(Dataset):\n","    \"\"\"\n","    ì§€ì •í•œ ì¹´í…Œê³ ë¦¬ë§Œ ìŠ¤ìº”í•˜ë„ë¡ ìˆ˜ì •ë¨\n","      Â· phase='train' â†’ bottle/train/good   (label=0)\n","      Â· phase='test'  â†’ bottle/test/good      (label=0)\n","                        bottle/test/<defect>/*(label=1)\n","    \"\"\"\n","    def __init__(self, root_dir:str, phase:str='train'):\n","        assert phase in ('train', 'test')\n","        self.phase = phase\n","        self.paths = []  # (img_path, label)\n","\n","        # 'bottle' ì¹´í…Œê³ ë¦¬ ê²½ë¡œë§Œ ì§ì ‘ ì§€ì •\n","        cat_path = Path(root_dir) / 'bottle'\n","\n","        if not cat_path.is_dir():\n","            # 'bottle' í´ë”ê°€ ì—†ì„ ê²½ìš° ì˜¤ë¥˜ ë°œìƒ\n","            raise FileNotFoundError(f\"ì§€ì •ëœ ê²½ë¡œì— 'bottle' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {cat_path}\")\n","\n","        if phase == 'train':\n","            # í›ˆë ¨ ë°ì´í„°: ì •ìƒ(good) ìƒ˜í”Œë§Œ ë¡œë“œ\n","            self.paths += [(p, 0) for p in glob(str(cat_path / 'train' / 'good' / '*.png'))]\n","        else:  # 'test'\n","            # í…ŒìŠ¤íŠ¸ ë°ì´í„°: ì •ìƒ(good) ìƒ˜í”Œ ë¡œë“œ\n","            self.paths += [(p, 0) for p in glob(str(cat_path / 'test' / 'good' / '*.png'))]\n","            # í…ŒìŠ¤íŠ¸ ë°ì´í„°: ë¹„ì •ìƒ(defect) ìƒ˜í”Œë“¤ ë¡œë“œ\n","            for defect in os.listdir(cat_path / 'test'):\n","                if defect == 'good':\n","                    continue\n","                defect_path = cat_path / 'test' / defect\n","                self.paths += [(p, 1) for p in glob(str(defect_path / '*.png'))]\n","\n","        self.tf = T.Compose([\n","            T.ToPILImage(),\n","            T.Resize((IMG_SIZE, IMG_SIZE)),\n","            T.ToTensor(),\n","            T.Normalize([0.5] * 3, [0.5] * 3)\n","        ])\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.paths[idx]\n","        img = plt.imread(img_path)\n","        if img.ndim == 2:  # grayscale â†’ 3-ch\n","            img = np.stack([img] * 3, -1)\n","        if img.max() <= 1:  # [0,1] â†’ [0,255]\n","            img = (img * 255).astype(np.uint8)\n","        # â— [ìˆ˜ì •] ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í•¨ê»˜ ë°˜í™˜\n","        return self.tf(img), label, img_path\n","\n","\n","def get_loaders_all(root_dir):\n","    train_ds = MVTecADMulti(root_dir, 'train')\n","    test_ds  = MVTecADMulti(root_dir, 'test')\n","\n","    train_loader = DataLoader(\n","        train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n","\n","    # â— [ìˆ˜ì •] í…ŒìŠ¤íŠ¸ ì‹œì—ëŠ” ë°ì´í„°ë¥¼ ì„ì§€ ì•Šë„ë¡ shuffle=Falseë¡œ ë³€ê²½\n","    test_loader  = DataLoader(\n","        test_ds, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    return train_loader, test_loader\n","\n"]},{"cell_type":"code","source":["# =============================================================\n","# 2.  ë„¤íŠ¸ì›Œí¬ ì •ì˜ (Skip-GANomaly)\n","# =============================================================\n","#TODO"],"metadata":{"id":"U9XgiEjn-HMU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =============================================================\n","# 3.  í•™ìŠµ ë£¨í”„ & í‰ê°€ í•¨ìˆ˜\n","# =============================================================\n","L_adv, L_rec, L_fm = nn.BCEWithLogitsLoss(), nn.L1Loss(), nn.L1Loss()\n","\n","def gradient_penalty(D, real, fake):\n","    a_weights = torch.rand(real.size(0),1,1,1, device=real.device)\n","    inter = (a_weights*real + (1-a_weights)*fake).requires_grad_(True)\n","    score = D(inter)\n","    grad  = autograd.grad(outputs=score, inputs=inter,\n","                          grad_outputs=torch.ones_like(score),\n","                          create_graph=True, retain_graph=True)[0]\n","    gp = ((grad.view(grad.size(0), -1).norm(2, dim=1) - 1)**2).mean()\n","    return gp\n","\n","def train_epoch(G,D,loader,optG,optD,lambda_rec=50,lambda_fm=10):\n","    G.train(); D.train(); g_tot=d_tot=0\n","    for imgs, _, _ in tqdm(loader, leave=False):\n","        imgs = imgs.to(DEVICE)\n","\n","        # --- D (maximize real-fake gap) ---\n","        optD.zero_grad()\n","        fake = G(imgs).detach()\n","        d_real = D(imgs)\n","        d_fake = D(fake)\n","        gp = gradient_penalty(D, imgs, fake)\n","        d_loss = -(d_real.mean() - d_fake.mean()) + lambda_GP*gp\n","        d_loss.backward(); optD.step()\n","\n","        # --- G (fool D + recon + feature-match) ---\n","        optG.zero_grad()\n","        fake = G(imgs)\n","        g_adv = -D(fake).mean()                     # WGAN generator loss\n","        _, feat_f = D(fake, True)\n","        _, feat_r = D(imgs, True)\n","        g_rec = L_rec(fake, imgs)\n","        g_fm  = L_fm(feat_f, feat_r.detach())\n","        g_loss = g_adv + lambda_rec*g_rec + lambda_fm*g_fm\n","        g_loss.backward(); optG.step()\n","\n","        g_tot += g_loss.item();  d_tot += d_loss.item()\n","    n=len(loader); return g_tot/n, d_tot/n\n","\n","@torch.inference_mode()\n","def get_scores(G, loader):\n","    G.eval(); scores=[]; labels=[]\n","    for imgs, lbl, _ in loader:\n","        imgs = imgs.to(DEVICE)\n","        err  = torch.mean((G(imgs) - imgs).abs(), dim=[1,2,3])\n","        scores += err.cpu().tolist(); labels += lbl\n","    return np.array(scores), np.array(labels)\n","\n","def fit_all(root_dir, save_path_g, save_path_d):\n","    \"\"\"\n","    ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ ì‹œì ì˜\n","    Generator(G)ì™€ Discriminator(D) ëª¨ë¸ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n","    \"\"\"\n","    tl, vl = get_loaders_all(root_dir)\n","    G, D = Generator().to(DEVICE), Discriminator().to(DEVICE)\n","    optG = torch.optim.Adam(G.parameters(), LR_G, betas=BETAS)\n","    optD = torch.optim.Adam(D.parameters(), LR_D, betas=BETAS)\n","\n","    best_auc = 0\n","    best_G_state = None\n","    best_D_state = None # [ì¶”ê°€] ìµœê³  ì„±ëŠ¥ Dì˜ ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í•  ë³€ìˆ˜\n","\n","    for ep in range(1, EPOCHS+1):\n","        g, d = train_epoch(G, D, tl, optG, optD)\n","        s, l = get_scores(G, vl)\n","        auc = roc_auc_score(l, s)\n","\n","        if auc > best_auc:\n","            best_auc = auc\n","            # [ìˆ˜ì •] Gì™€ Dì˜ ê°€ì¤‘ì¹˜ë¥¼ í•¨ê»˜ ì €ì¥\n","            best_G_state = copy.deepcopy(G.state_dict())\n","            best_D_state = copy.deepcopy(D.state_dict())\n","            torch.save(best_G_state, save_path_g)\n","            torch.save(best_D_state, save_path_d)\n","\n","        print(f'[Ep {ep:03d}] G:{g:.3f}  D:{d:.3f}  AUC:{auc:.4f} (best {best_auc:.4f})')\n","\n","    print(f'\\nDone! best AUC: {best_auc:.4f}')\n","\n","    # [ìˆ˜ì •] Gì™€ D ëª¨ë‘ì— ìµœê³  ì„±ëŠ¥ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œ\n","    if best_G_state and best_D_state:\n","        G.load_state_dict(best_G_state)\n","        D.load_state_dict(best_D_state)\n","\n","    # [ìˆ˜ì •] Gì™€ D ëª¨ë¸ ê°ì²´ë¥¼ ëª¨ë‘ ë°˜í™˜\n","    return G, D\n"],"metadata":{"id":"8VFtsWq7auab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =============================================================\n","# 4.  í•™ìŠµ ì‹¤í–‰\n","# =============================================================\n","\n","# Gì™€ Dì˜ ì €ì¥ ê²½ë¡œë¥¼ ê°ê° ì •ì˜í•©ë‹ˆë‹¤.\n","G_SAVE_NAME = 'best_skipgan_all.pt'\n","D_SAVE_NAME = 'best_skipgan_all_D.pt'\n","\n","# 2ê°œì˜ ì €ì¥ ê²½ë¡œë¥¼ ëª¨ë‘ ì¸ìë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.\n","best_G, best_D = fit_all(ROOT_DIR, G_SAVE_NAME, D_SAVE_NAME)"],"metadata":{"id":"9yRgx1HEaw8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =============================================================\n","# 5.  ì¬êµ¬ì„± ì‹œê°í™” (í•™ìŠµ í›„)\n","# =============================================================\n","SAVE_NAME = '/content/best_skipgan_all.pt'\n","\n","@torch.inference_mode()\n","def show_recon(G, loader, n=6):\n","    G.eval()\n","    imgs, _, _ = next(iter(loader))\n","    imgs = imgs[:n].to(DEVICE)\n","\n","    recon = G(imgs)\n","    imgs, recon = imgs.cpu()*0.5+0.5, recon.cpu()*0.5+0.5\n","    plt.figure(figsize=(n*2,4))\n","    for i in range(n):\n","        plt.subplot(2,n,i+1);     plt.imshow(imgs[i].permute(1,2,0));   plt.axis('off')\n","        plt.subplot(2,n,n+i+1);   plt.imshow(recon[i].permute(1,2,0));  plt.axis('off')\n","    plt.suptitle('Input (top) vs Reconstruction (bottom)'); plt.show()\n","\n","# ğŸ’¡ ì‚¬ìš© ì˜ˆ: íŒŒì¼ ë¡œë“œ ê³¼ì • ì—†ì´, ìœ„ì—ì„œ ë°˜í™˜ë°›ì€ `best_G_model`ì„ ì¦‰ì‹œ ì‚¬ìš©\n","_, test_loader = get_loaders_all(ROOT_DIR)\n","show_recon(best_G, test_loader)\n","\n","# ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì •ìƒ/ì´ìƒ ê°œìˆ˜ í™•ì¸\n","num_norm = sum(1 for _, y, _ in test_loader.dataset if y == 0)\n","num_anom = sum(1 for _, y, _ in test_loader.dataset if y == 1)\n","print(f\"âœ” ì •ìƒ(good)   : {num_norm:,}\")\n","print(f\"âœ” ì´ìƒ(defect) : {num_anom:,}\")"],"metadata":{"id":"6Nhi1-4y9PJ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì •ìƒ/ì´ìƒ ê°œìˆ˜ í™•ì¸\n","num_norm = sum(1 for path, label in test_loader.dataset.paths if label == 0)\n","num_anom = sum(1 for path, label in test_loader.dataset.paths if label == 1)\n","print(f\"âœ” ì •ìƒ(good)   : {num_norm:,}\")\n","print(f\"âœ” ì´ìƒ(defect) : {num_anom:,}\")\n"],"metadata":{"id":"MlUAxFn3Bi_9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CwbN5iW0CqAt"},"outputs":[],"source":["# =============================================================\n","# 6.  í…ŒìŠ¤íŠ¸ & ì‹œê°í™”\n","# =============================================================\n","import torch.nn.functional as F\n","\n","# â— [ìˆ˜ì •] íŒŒì¼ ë¡œë“œ ë¸”ë¡ ì „ì²´ë¥¼ ì‚­ì œí•˜ê³ ,\n","# ì´ì „ ë‹¨ê³„ì—ì„œ ë°˜í™˜ë°›ì€ ëª¨ë¸ ê°ì²´ë¥¼ ì¦‰ì‹œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n","best_G.eval()\n","best_D.eval()\n","\n","# Anomaly Score ê³„ì‚°ì„ ìœ„í•œ ê°€ì¤‘ì¹˜ (lambda)\n","LAMBDA_SCORE = 0.1\n","\n","# â‘¡ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì „ì²´ì— ëŒ€í•´ Anomaly Score ê³„ì‚°\n","scores, labels, paths = [], [], []\n","with torch.no_grad():\n","    # test_loaderëŠ” ë¯¸ë¦¬ ë¡œë“œë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n","    _, test_loader = get_loaders_all(ROOT_DIR)\n","\n","    for imgs, lbls, batch_paths in tqdm(test_loader, 'Testing'):\n","        imgs_gpu = imgs.to(DEVICE)\n","\n","        # 1. ì¬êµ¬ì„± ì´ë¯¸ì§€ ìƒì„± (best_G ì‚¬ìš©)\n","        recons = best_G(imgs_gpu)\n","\n","        # 2. ì¬êµ¬ì„± ì˜¤ì°¨ (L_con) ê³„ì‚°: |x - G(x)|\n","        err_rec = torch.mean(torch.abs(imgs_gpu - recons), dim=[1,2,3])\n","\n","        # 3. íŒë³„ì íŠ¹ì§• ì¶”ì¶œ (best_D ì‚¬ìš©)\n","        _, feat_real = best_D(imgs_gpu, return_feat=True)\n","        _, feat_fake = best_D(recons, return_feat=True)\n","\n","        # 4. íŠ¹ì§• ê³µê°„ ì˜¤ì°¨ (L_enc) ê³„ì‚°: |f_D(x) - f_D(G(x))|\n","        err_enc = torch.mean(torch.abs(feat_real - feat_fake), dim=1)\n","\n","        # 5. ìµœì¢… ì´ìƒì¹˜ ì ìˆ˜ ê³„ì‚°\n","        batch_scores = (1 - LAMBDA_SCORE) * err_rec + LAMBDA_SCORE * err_enc\n","\n","        scores.append(batch_scores.cpu().numpy())\n","        labels.append(lbls.numpy())\n","        paths += batch_paths\n","\n","scores = np.concatenate(scores)\n","labels = np.concatenate(labels)\n","\n","\n","# â‘¢ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹œê°í™” (ì´í•˜ ë¡œì§ì€ ë™ì¼)\n","# ì •ìƒ ë°ì´í„°ì˜ ì ìˆ˜ ë¶„í¬ì—ì„œ 95% ì§€ì ì„ ì„ê³„ê°’ìœ¼ë¡œ ì„¤ì •\n","THRESH = np.percentile(scores[labels == 0], 95)\n","\n","# ---------- (1) ì ìˆ˜ ë¶„í¬ ì‹œê°í™” ----------\n","hist_n, edges = np.histogram(scores[labels == 0], bins=60, range=(scores.min(), scores.max()))\n","hist_a, _     = np.histogram(scores[labels == 1], bins=edges)\n","centers       = (edges[:-1] + edges[1:]) / 2\n","bar_width     = centers[1] - centers[0]\n","\n","plt.figure(figsize=(8, 5))\n","plt.bar(centers, hist_n, width=bar_width, label='Normal',  alpha=.7)\n","plt.bar(centers, hist_a, width=bar_width, label='Anomaly', alpha=.7, bottom=hist_n)\n","plt.axvline(THRESH, ls='--', lw=2, color='k', label=f'Threshold={THRESH:.4f}')\n","plt.xlabel('Anomaly Score'); plt.ylabel('Count')\n","plt.title ('Anomaly Score Distribution (Test Set)'); plt.legend()\n","plt.tight_layout(); plt.show()\n","\n","\n","# ---------- (2) ì •ìƒÂ·ì´ìƒ íŒë³„ ì˜ˆì‹œ ì‹œê°í™” ----------\n","def pick_idxs(labels, scores, thresh, n_each=5):\n","    # ì •ìƒìœ¼ë¡œ íŒë³„ëœ ì •ìƒ ìƒ˜í”Œ (True Negative)\n","    idx_norm = np.where((labels == 0) & (scores < thresh))[0]\n","    # ì´ìƒìœ¼ë¡œ íŒë³„ëœ ì´ìƒ ìƒ˜í”Œ (True Positive)\n","    idx_anom = np.where((labels == 1) & (scores > thresh))[0]\n","\n","    # ê° ê·¸ë£¹ì—ì„œ n_eachê°œì”© ëœë¤ìœ¼ë¡œ ì„ íƒ\n","    # ìƒ˜í”Œ ìˆ˜ê°€ ë¶€ì¡±í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ replace=True ì„¤ì •\n","    sel_norm = np.random.choice(idx_norm, n_each, replace=len(idx_norm) < n_each)\n","    sel_anom = np.random.choice(idx_anom, n_each, replace=len(idx_anom) < n_each)\n","\n","    return np.concatenate([sel_norm, sel_anom])\n","\n","# ì‹œê°í™”í•  ìƒ˜í”Œ ì¸ë±ìŠ¤ ì„ íƒ\n","sel_indices = pick_idxs(labels, scores, THRESH, 5)\n","\n","fig, axes = plt.subplots(2, 5, figsize=(15, 6.5))\n","axes = axes.flatten()\n","for i, idx in enumerate(sel_indices):\n","    img = plt.imread(paths[idx])[..., :3]\n","    ax = axes[i]\n","    ax.imshow(img)\n","    ax.axis('off')\n","\n","    # ì• 5ê°œëŠ” Normal, ë’¤ 5ê°œëŠ” Anomaly\n","    label_str = 'Normal (TN)' if i < 5 else 'Anomaly (TP)'\n","    ax.set_title(f\"{label_str}\\nScore={scores[idx]:.4f}\")\n","\n","plt.suptitle('Anomaly Detection Examples (Correct Predictions)')\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","plt.show()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"O0CAqCFZ-5ki"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMulE5aGZf287AsDSs/yTgN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}