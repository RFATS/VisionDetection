{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyMa2/WbbmdtZJc8gbGhdupT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"b_tjBv7Wi8kq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 0. 의존성\n","# ==================================================\n","import os, random, time\n","from pathlib import Path\n","from glob import glob\n","from typing import List, Tuple\n","\n","import numpy as np\n","from PIL import Image\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import torch.nn as nn\n","import torch.nn.functional as F                         # 모델 연산용\n","import torchvision.transforms as T\n","import torchvision.transforms.functional as TF          # 이미지 변환용\n","\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","import matplotlib.patches as mpatches\n","import math\n","\n"],"metadata":{"id":"hOxA6aVVv8Uv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 1. 전역 설정 (필요 시 수정)\n","# ==================================================\n","ROOT_DIR    = \"/content/drive/MyDrive/Data/MVTecAD\"  # 데이터셋 루트\n","IMG_SIZE    = 256          # 이미지 리사이즈 크기\n","BATCH_SIZE  = 32\n","NUM_WORKERS = 4\n","LR          = 1e-4\n","EPOCHS      = 100\n","VAL_SPLIT   = 0.2\n","PRINT_FREQ  = 50           # 학습 중 log 출력 간격\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"HXAms2mJce-U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 2. Dataset\n","# ==================================================\n","class MVTecSegDataset(Dataset):\n","    \"\"\"MVTecAD Pixel‑wise Segmentation 전용\n","        test/<defect>/*.png  → 입력 이미지\n","        ground_truth/<defect>/*_mask.png → 바이너리 마스크\n","        good 샘플은 기본 제외(include_good=False)\n","    \"\"\"\n","    IMG_EXT = (\".png\", \".jpg\", \".jpeg\")\n","\n","    def __init__(self, root_dir: str, include_good: bool=False, img_size: int=256):\n","        self.samples: List[Tuple[str, str]] = []   # (image_path, mask_path)\n","        self.img_size = img_size\n","\n","        root = Path(root_dir)\n","        for cls_dir in sorted(root.iterdir()):\n","            if not cls_dir.is_dir():\n","                continue\n","            test_dir = cls_dir / \"test\"\n","            gt_dir   = cls_dir / \"ground_truth\"\n","            if not (test_dir.exists() and gt_dir.exists()):\n","                continue\n","\n","            for defect in sorted(d.name for d in test_dir.iterdir() if d.is_dir()):\n","                if defect == \"good\" and not include_good:\n","                    continue\n","                # ---------- 이미지 / 마스크 매칭 ----------\n","                for img_path in (test_dir / defect).glob(\"*\"):\n","                    if img_path.suffix.lower() not in self.IMG_EXT:\n","                        continue\n","                    if defect == \"good\":\n","                        mask_path = None   # 정상 → 0‑mask\n","                    else:\n","                        stem      = img_path.stem\n","                        mask_path = gt_dir / defect / f\"{stem}_mask.png\"\n","                        if not mask_path.exists():\n","                            continue\n","                    self.samples.append((str(img_path), str(mask_path) if mask_path else None))\n","\n","        print(f\"총 {len(self.samples)}개 이미지/마스크 쌍 로드 완료\")\n","\n","        # 변환 파이프라인 정의\n","        self.img_tf = T.Compose([\n","            T.Resize((img_size, img_size), interpolation=T.InterpolationMode.BILINEAR),\n","            T.ToTensor(),                                   # (3,H,W) 0~1\n","        ])\n","        self.mask_tf = T.Compose([\n","            T.Resize((img_size, img_size), interpolation=T.InterpolationMode.NEAREST),\n","            T.ToTensor(),                                   # (1,H,W) 0~1\n","        ])\n","\n","    # 필수 메서드 -----------------------------------\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        ipath, mpath = self.samples[idx]\n","        # ----- 이미지 로드 -----\n","        img  = Image.open(ipath).convert(\"RGB\")\n","        imgT = self.img_tf(img)\n","        # ----- 마스크 로드 -----\n","        if mpath is None:\n","            mask = Image.new(\"L\", img.size, 0)    # 전부 0\n","        else:\n","            mask = Image.open(mpath).convert(\"L\")\n","        maskT = self.mask_tf(mask)                 # (1,H,W)\n","        return imgT, maskT\n","\n"],"metadata":{"id":"I-DjrlJ4cfBJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 3. DataLoader 구성\n","# ==================================================\n","full_ds = MVTecSegDataset(ROOT_DIR, include_good=False, img_size=IMG_SIZE)\n","val_len   = int(len(full_ds) * VAL_SPLIT)\n","train_len = len(full_ds) - val_len\n","train_set, val_set = random_split(full_ds, [train_len, val_len], generator=torch.Generator().manual_seed(42))\n","\n","def collate_fn(batch):\n","    imgs, masks = zip(*batch)\n","    return torch.stack(imgs), torch.stack(masks)        # (B,3,H,W) (B,1,H,W)\n","\n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_fn)\n","val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_fn)\n","\n"],"metadata":{"id":"H5po-YJlcfEC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 4. 모델 (경량 U‑Net)\n","# ==================================================\n","# TODO"],"metadata":{"id":"HvEa8lLNcfHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 5. 손실 & 지표\n","# ==================================================\n","# TODO"],"metadata":{"id":"5_jeOov0cnqF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 6. train & validate 함수\n","# ==================================================\n","# TODO"],"metadata":{"id":"rzBRJHpjcntM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# ★ 세그멘테이션 오버레이 시각화 (배치 크기 무관)\n","# ==================================================\n","\n","@torch.no_grad()\n","def visualize_overlay(model, loader, device=DEVICE, n=6, alpha=0.45):\n","    \"\"\"\n","    • 원본 이미지 위에 GT(녹색) · 예측(빨간색) 마스크를 반투명 오버레이\n","    • n 장이 확보될 때까지 DataLoader에서 연속적으로 가져옴\n","    • 최대 4장씩 가로로 배치\n","    \"\"\"\n","    model.eval()\n","\n","    # ---------- n장 모으기 ----------\n","    imgs_acc, masks_acc, preds_acc = [], [], []\n","    for imgs, masks in loader:\n","        imgs_acc.append(imgs)\n","        masks_acc.append(masks)\n","        preds_acc.append((torch.sigmoid(model(imgs.to(device))) > 0.5).cpu())\n","        if sum(b.size(0) for b in imgs_acc) >= n:\n","            break\n","\n","    imgs  = torch.cat(imgs_acc)[:n]   # (n,3,H,W)\n","    masks = torch.cat(masks_acc)[:n]  # (n,1,H,W)\n","    preds = torch.cat(preds_acc)[:n]  # (n,1,H,W)\n","\n","    # ---------- 오버레이 ----------\n","    gt_color   = np.array([0, 1, 0])   # green\n","    pred_color = np.array([1, 0, 0])   # red\n","\n","    cols = 4\n","    rows = math.ceil(n / cols)\n","    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))\n","    axes = axes.flatten()        # 2D → 1D 배열로 편하게 인덱싱\n","\n","    for i in range(n):\n","        img_np = imgs[i].permute(1, 2, 0).numpy()\n","        gt_np  = masks[i, 0].numpy()\n","        pr_np  = preds[i, 0].numpy()\n","\n","        overlay = img_np.copy()\n","        overlay[gt_np == 1] = (1 - alpha) * overlay[gt_np == 1] + alpha * gt_color\n","        overlay[pr_np == 1] = (1 - alpha) * overlay[pr_np == 1] + alpha * pred_color\n","\n","        axes[i].imshow(overlay)\n","        axes[i].axis(\"off\")\n","        axes[i].set_title(f\"Sample {i}\")\n","\n","    # 남는 서브플롯은 비우기\n","    for j in range(n, rows * cols):\n","        axes[j].axis(\"off\")\n","\n","    # 범례\n","    green_patch = mpatches.Patch(color=\"green\", label=\"Ground Truth\")\n","    red_patch   = mpatches.Patch(color=\"red\",   label=\"Prediction\")\n","    plt.legend(handles=[green_patch, red_patch],\n","               bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"wS2ZP9PjwWwf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Best 모델 로드 후 오버레이 시각화\n","model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n","visualize_overlay(model, val_loader, n=16, alpha=0.4)\n"],"metadata":{"id":"YN8P7w5ix4Xx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"E1hWhw_hyzZj"},"execution_count":null,"outputs":[]}]}