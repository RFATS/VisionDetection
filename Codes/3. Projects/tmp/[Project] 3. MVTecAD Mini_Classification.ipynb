{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyM0S9LWL1PKB21SNHiweq7t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vhEuHkBolbKf","executionInfo":{"status":"ok","timestamp":1745470626099,"user_tz":-540,"elapsed":1355,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"57f3c10c-f8a4-49a4-aa48-d9c728e7563d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# ==================================================\n","# 0. 의존성\n","# ==================================================\n","import os, random, time\n","from pathlib import Path\n","from collections import Counter\n","from PIL import Image\n","import torch, torch.nn as nn\n","from torch.utils.data     import Dataset, DataLoader, WeightedRandomSampler\n","from torchvision          import transforms, models\n","\n","# --------------------------------------------------\n","ROOT         = \"/content/drive/MyDrive/Data/MVTecAD/bottle\"\n","TRAIN_DIR    = os.path.join(ROOT, \"train\")\n","TEST_DIR     = os.path.join(ROOT, \"test\")\n","\n","IMG_SIZE     = # TODO\n","BATCH_SIZE   = # TODO\n","NUM_EPOCHS   = # TODO\n","VAL_RATIO    = 0.2\n","LR           = # TODO\n","DEVICE       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"Y9wnP8oj6Z2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 1. 전역 클래스 매핑 + 전체 샘플 리스트\n","# ==================================================\n","def scan_classes(*dirs):\n","    return sorted({p.name for d in dirs for p in Path(d).iterdir() if p.is_dir()})\n","\n","classes        = scan_classes(TRAIN_DIR, TEST_DIR)\n","class_to_idx   = {cls: i for i, cls in enumerate(classes)}\n","num_classes    = len(classes)\n","print(\"라벨:\", classes)\n","\n","def samples_from(root):\n","    return [(str(p), class_to_idx[p.parent.name])\n","            for p in Path(root).rglob(\"*.*\") if p.is_file() and p.parent.name in class_to_idx]\n","\n","all_samples = samples_from(TRAIN_DIR) + samples_from(TEST_DIR)\n","random.shuffle(all_samples)                       # 시드 고정했으므로 재현 가능\n","print(f\"총 이미지: {len(all_samples)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tBlJxkx_6Z4v","executionInfo":{"status":"ok","timestamp":1745470629056,"user_tz":-540,"elapsed":90,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"a0de777c-9e78-4926-ce4d-6913cf8949e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["라벨: ['broken_large', 'broken_small', 'contamination', 'good']\n","총 이미지: 292\n"]}]},{"cell_type":"code","source":["# ==================================================\n","# 2. 학습/검증 분할\n","# ==================================================\n","val_size   = int(len(all_samples) * VAL_RATIO)\n","val_samples, train_samples = all_samples[:val_size], all_samples[val_size:]\n","\n","print(f\"학습 {len(train_samples)}  |  검증 {len(val_samples)}\")"],"metadata":{"id":"ZiYxKUhz6Z7U","executionInfo":{"status":"ok","timestamp":1745470629060,"user_tz":-540,"elapsed":3,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0803bc2-93e8-403f-846b-5db9a3b1e18e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["학습 234  |  검증 58\n"]}]},{"cell_type":"code","source":["# ==================================================\n","# 3. 커스텀 데이터셋\n","# ==================================================\n","\n","# ImageNet-1K (ILSVRC 2012)\n","mean, std = [0.485,0.456,0.406], [0.229,0.224,0.225]\n","train_tf  = transforms.Compose([\n","    transforms.Resize((#TODO, #TODO)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(#TODO),\n","    transforms.ToTensor(), transforms.Normalize(mean, std),\n","])\n","val_tf    = transforms.Compose([\n","    transforms.Resize((#TODO, #TODO)),\n","    transforms.ToTensor(), transforms.Normalize(mean, std),\n","])\n","\n","class SimpleImageDS(Dataset):\n","    def __init__(self, samples, transform=None):\n","        self.samples, self.t = samples, transform\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        path, label = self.samples[idx]\n","        img = Image.open(path).convert(\"RGB\")\n","\n","        return (self.t(img) if self.t else img), label\n","\n","train_set = SimpleImageDS(#TODO, #TODO)\n","val_set   = SimpleImageDS(#TODO, #TODO )"],"metadata":{"id":"iMxxqkhwBjW8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 4. 클래스 가중치 & Weighted Sampler\n","# ==================================================\n","cnt          = Counter([lbl for _, lbl in train_samples])\n","total_train  = len(train_samples)\n","class_weights = torch.tensor(\n","    [ (total_train / cnt[i]) if cnt[i]>0 else 0.0 for i in range(num_classes)],\n","    dtype=torch.float, device=DEVICE)\n","\n","sample_weights = [class_weights[lbl].item() for _, lbl in train_samples]\n","sampler = WeightedRandomSampler(#TODO, num_samples=#TODO, replacement=True)\n","\n","train_loader = DataLoader(#TODO, batch_size=#TODO, sampler=#TODO,\n","                          num_workers=4, pin_memory=True)\n","val_loader   = DataLoader(#TODO, batch_size=#TODO, shuffle=False,\n","                          num_workers=4, pin_memory=True)"],"metadata":{"id":"LtYTWQn_GbYs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 5. 모델 (EfficientNet-B0)\n","# ==================================================\n","model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n","for p in model.parameters():         # 백본 고정\n","    p.requires_grad = False\n","model.classifier[1] = nn.Linear(model.classifier[1].in_features, #TODO)\n","model.to(DEVICE)\n","\n","criterion = nn.CrossEntropyLoss(weight=#TODO)\n","optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=#TODO)\n"],"metadata":{"id":"3s_kdDMg6Z-H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 6. 학습 루프 (변경 없음)\n","# ==================================================\n","def run_epoch(loader, train=True):\n","    model.train() if train else model.eval()\n","    loss_sum = correct = total = 0\n","    for x, y in loader:\n","        x, y = x.to(DEVICE), y.to(DEVICE)\n","        with torch.set_grad_enabled(train):\n","            out  = #TODO\n","            loss = #TODO\n","            if train:\n","                optimizer.zero_grad();\n","                loss.backward();\n","                optimizer.step()\n","        loss_sum += loss.item() * x.size(0)\n","        correct  += (out.argmax(1)==y).sum().item()\n","        total    += y.size(0)\n","    return loss_sum/total, correct/total\n","\n","best_acc = 0\n","for e in range(1, NUM_EPOCHS+1):\n","    t0 = time.time()\n","    tr_loss,tr_acc = run_epoch(train_loader,True)\n","    va_loss,va_acc = run_epoch(val_loader,  False)\n","    if va_acc > best_acc:\n","        best_acc = va_acc; torch.save(model.state_dict(),\"best_effb0_cls.pth\")\n","    print(f\"[{e:02d}] Train {tr_loss:.4f}/{tr_acc:.3f} | \"\n","          f\"Val {va_loss:.4f}/{va_acc:.3f} | {time.time()-t0:.1f}s\")\n","\n","print(\"최고 검증 정확도:\", best_acc )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87JZxeIB6aDl","executionInfo":{"status":"ok","timestamp":1745470762616,"user_tz":-540,"elapsed":132961,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"736b74c8-182a-4566-dd24-474cbde719bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[01] Train 1.1683/0.427 | Val 1.2690/0.138 | 3.4s\n","[02] Train 0.9037/0.526 | Val 1.1452/0.172 | 3.3s\n","[03] Train 0.7961/0.581 | Val 1.0530/0.190 | 3.4s\n","[04] Train 0.7727/0.594 | Val 0.9873/0.155 | 3.3s\n","[05] Train 0.7165/0.590 | Val 0.9231/0.190 | 3.3s\n","[06] Train 0.6212/0.662 | Val 0.9474/0.155 | 3.3s\n","[07] Train 0.5351/0.645 | Val 0.9060/0.155 | 3.3s\n","[08] Train 0.4842/0.650 | Val 0.9019/0.172 | 3.3s\n","[09] Train 0.5375/0.611 | Val 0.8741/0.172 | 3.3s\n","[10] Train 0.4849/0.632 | Val 0.8458/0.207 | 3.4s\n","[11] Train 0.4741/0.662 | Val 0.8095/0.224 | 3.4s\n","[12] Train 0.4518/0.641 | Val 0.7846/0.310 | 3.3s\n","[13] Train 0.4580/0.632 | Val 0.7704/0.379 | 3.3s\n","[14] Train 0.4390/0.675 | Val 0.7673/0.379 | 3.3s\n","[15] Train 0.4468/0.667 | Val 0.7356/0.552 | 3.4s\n","[16] Train 0.5278/0.645 | Val 0.7472/0.397 | 3.3s\n","[17] Train 0.3719/0.705 | Val 0.7458/0.379 | 3.3s\n","[18] Train 0.3463/0.748 | Val 0.6878/0.776 | 3.4s\n","[19] Train 0.3694/0.705 | Val 0.6530/0.776 | 3.3s\n","[20] Train 0.4171/0.654 | Val 0.6361/0.879 | 3.3s\n","[21] Train 0.3688/0.744 | Val 0.6568/0.810 | 3.3s\n","[22] Train 0.3448/0.748 | Val 0.6668/0.879 | 3.4s\n","[23] Train 0.3375/0.756 | Val 0.6542/0.828 | 3.3s\n","[24] Train 0.3068/0.778 | Val 0.5995/0.931 | 3.3s\n","[25] Train 0.3974/0.761 | Val 0.6194/0.931 | 3.3s\n","[26] Train 0.3711/0.692 | Val 0.5985/0.897 | 3.3s\n","[27] Train 0.3472/0.782 | Val 0.6144/0.931 | 3.3s\n","[28] Train 0.2505/0.799 | Val 0.5746/0.931 | 3.3s\n","[29] Train 0.2995/0.786 | Val 0.5747/0.931 | 3.4s\n","[30] Train 0.2622/0.846 | Val 0.5678/0.931 | 3.3s\n","[31] Train 0.3028/0.829 | Val 0.5943/0.931 | 3.3s\n","[32] Train 0.3011/0.774 | Val 0.5530/0.931 | 3.3s\n","[33] Train 0.3336/0.748 | Val 0.5221/0.931 | 3.4s\n","[34] Train 0.2735/0.795 | Val 0.5312/0.931 | 3.3s\n","[35] Train 0.2613/0.897 | Val 0.5335/0.931 | 3.3s\n","[36] Train 0.3231/0.786 | Val 0.5402/0.914 | 3.4s\n","[37] Train 0.2620/0.816 | Val 0.5443/0.914 | 3.3s\n","[38] Train 0.2483/0.782 | Val 0.5359/0.931 | 3.3s\n","[39] Train 0.3027/0.782 | Val 0.5615/0.914 | 3.3s\n","[40] Train 0.3016/0.859 | Val 0.5972/0.862 | 3.4s\n","최고 검증 정확도: 0.9310344827586207\n"]}]},{"cell_type":"code","source":["# ==================================================\n","# 7. Test Visualization  ── 검증(=test) 이미지 예측 결과 보기\n","# ==================================================\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# ① 최고 성능 모델 불러오기\n","model.load_state_dict(torch.load(\"best_effb0_cls.pth\", map_location=DEVICE))\n","model.eval()\n","\n","# ② 시각화 함수\n","def unnormalize(img_tensor):\n","    \"\"\"(C,H,W) 텐서를 0~1 범위 numpy 이미지로 복원\"\"\"\n","    mean = torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)\n","    std  = torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1)\n","    img = img_tensor.cpu() * std + mean\n","    return img.permute(1,2,0).numpy().clip(0,1)\n","\n","def show_predictions(loader, num_images=8):\n","    shown = 0\n","    rows  = int(np.ceil(num_images / 4))\n","    plt.figure(figsize=(16, 4 * rows))\n","\n","    with torch.no_grad():\n","        for imgs, labels in loader:\n","            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n","            probs = torch.softmax(model(imgs), dim=1)\n","            preds = probs.argmax(1).cpu()\n","            probs = probs.cpu()\n","\n","            for i in range(imgs.size(0)):\n","                if shown >= num_images: break\n","                shown += 1\n","\n","                plt.subplot(rows, 4, shown)\n","                plt.imshow(unnormalize(imgs[i]))\n","                gt   = classes[labels[i].item()]\n","                pred = classes[preds[i].item()]\n","                conf = probs[i, preds[i]].item()\n","                title = f\"Pred: {pred} ({conf:.2f})\\nGT: {gt}\"\n","                plt.title(title, fontsize=9)\n","                plt.axis(\"off\")\n","            if shown >= num_images: break\n","    plt.tight_layout()\n","    plt.show()\n","\n","# ③ 호출\n","show_predictions(val_loader, num_images=32)   # ← 원하는 수로 조정\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1bZE0IvSTyGXrZwCU1X93rzBTd1JqZryb"},"id":"nNZmFQ7RAym3","executionInfo":{"status":"ok","timestamp":1745471354326,"user_tz":-540,"elapsed":6305,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"ddddd93f-1ae7-4ad8-c4ca-9a739f12806c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"U0Ea4iEPHHZC"},"execution_count":null,"outputs":[]}]}