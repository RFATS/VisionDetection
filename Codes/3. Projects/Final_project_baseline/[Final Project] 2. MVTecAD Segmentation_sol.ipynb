{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyPUtHxpFwIATXxrJskl35lT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_tjBv7Wi8kq","executionInfo":{"status":"ok","timestamp":1745718718742,"user_tz":-540,"elapsed":1317,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"f7e78388-3f3a-432b-fdfc-933cf08c9d49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# ==================================================\n","# 0. 의존성\n","# ==================================================\n","import os, random, time\n","from pathlib import Path\n","from glob import glob\n","from typing import List, Tuple\n","\n","import numpy as np\n","from PIL import Image\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import torch.nn as nn\n","import torch.nn.functional as F                         # 모델 연산용\n","import torchvision.transforms as T\n","import torchvision.transforms.functional as TF          # 이미지 변환용\n","\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","import matplotlib.patches as mpatches\n","import math"],"metadata":{"id":"d8D_b6AVBANH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 1. 전역 설정 (필요 시 수정)\n","# ==================================================\n","ROOT_DIR    = \"/content/drive/MyDrive/Data/MVTecAD\"  # 데이터셋 루트\n","IMG_SIZE    = 256          # 이미지 리사이즈 크기\n","BATCH_SIZE  = 32\n","NUM_WORKERS = 4\n","LR          = 1e-4\n","EPOCHS      = 100\n","VAL_SPLIT   = 0.2\n","PRINT_FREQ  = 50           # 학습 중 log 출력 간격\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"WVG096anAt1c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 2. Dataset\n","# ==================================================\n","class MVTecSegDataset(Dataset):\n","    \"\"\"MVTecAD Pixel‑wise Segmentation 전용\n","        test/<defect>/*.png  → 입력 이미지\n","        ground_truth/<defect>/*_mask.png → 바이너리 마스크\n","        good 샘플은 기본 제외(include_good=False)\n","    \"\"\"\n","    IMG_EXT = (\".png\", \".jpg\", \".jpeg\")\n","\n","    def __init__(self, root_dir: str, include_good: bool=False, img_size: int=256):\n","        self.samples: List[Tuple[str, str]] = []   # (image_path, mask_path)\n","        self.img_size = img_size\n","\n","        root = Path(root_dir)\n","        for cls_dir in sorted(root.iterdir()):\n","            if not cls_dir.is_dir():\n","                continue\n","            test_dir = cls_dir / \"test\"\n","            gt_dir   = cls_dir / \"ground_truth\"\n","            if not (test_dir.exists() and gt_dir.exists()):\n","                continue\n","\n","            for defect in sorted(d.name for d in test_dir.iterdir() if d.is_dir()):\n","                if defect == \"good\" and not include_good:\n","                    continue\n","                # ---------- 이미지 / 마스크 매칭 ----------\n","                for img_path in (test_dir / defect).glob(\"*\"):\n","                    if img_path.suffix.lower() not in self.IMG_EXT:\n","                        continue\n","                    if defect == \"good\":\n","                        mask_path = None   # 정상 → 0‑mask\n","                    else:\n","                        stem      = img_path.stem\n","                        mask_path = gt_dir / defect / f\"{stem}_mask.png\"\n","                        if not mask_path.exists():\n","                            continue\n","                    self.samples.append((str(img_path), str(mask_path) if mask_path else None))\n","\n","        print(f\"총 {len(self.samples)}개 이미지/마스크 쌍 로드 완료\")\n","\n","        # 변환 파이프라인 정의\n","        self.img_tf = T.Compose([\n","            T.Resize((img_size, img_size), interpolation=T.InterpolationMode.BILINEAR),\n","            T.ToTensor(),                                   # (3,H,W) 0~1\n","        ])\n","        self.mask_tf = T.Compose([\n","            T.Resize((img_size, img_size), interpolation=T.InterpolationMode.NEAREST),\n","            T.ToTensor(),                                   # (1,H,W) 0~1\n","        ])\n","\n","    # 필수 메서드 -----------------------------------\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        ipath, mpath = self.samples[idx]\n","        # ----- 이미지 로드 -----\n","        img  = Image.open(ipath).convert(\"RGB\")\n","        imgT = self.img_tf(img)\n","        # ----- 마스크 로드 -----\n","        if mpath is None:\n","            mask = Image.new(\"L\", img.size, 0)    # 전부 0\n","        else:\n","            mask = Image.open(mpath).convert(\"L\")\n","        maskT = self.mask_tf(mask)                 # (1,H,W)\n","        return imgT, maskT"],"metadata":{"id":"8DNwhv80AuY0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 3. DataLoader 구성\n","# ==================================================\n","full_ds = MVTecSegDataset(ROOT_DIR, include_good=False, img_size=IMG_SIZE)\n","val_len   = int(len(full_ds) * VAL_SPLIT)\n","train_len = len(full_ds) - val_len\n","train_set, val_set = random_split(full_ds, [train_len, val_len], generator=torch.Generator().manual_seed(42))\n","\n","def collate_fn(batch):\n","    imgs, masks = zip(*batch)\n","    return torch.stack(imgs), torch.stack(masks)        # (B,3,H,W) (B,1,H,W)\n","\n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_fn)\n","val_loader   = DataLoader(val_set,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, collate_fn=collate_fn)\n"],"metadata":{"id":"8w23K3oxAubu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 4. 모델 (경량 U‑Net)\n","# ==================================================\n","class DoubleConv(nn.Module):\n","    \"\"\"Conv‑BN‑ReLU ×2 블록\"\"\"\n","    def __init__(self, in_c, out_c):\n","        super().__init__()\n","        self.block = nn.Sequential(\n","            nn.Conv2d(in_c, out_c, 3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n","            nn.Conv2d(out_c, out_c, 3, padding=1, bias=False),\n","            nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n","        )\n","    def forward(self, x):\n","        return self.block(x)\n","\n","class UNet(nn.Module):\n","    def __init__(self, in_c=3, out_c=1, feat=[64,128,256,512]):\n","        super().__init__()\n","        self.downs = nn.ModuleList()\n","        self.ups   = nn.ModuleList()\n","        # 인코더(Down)\n","        for f in feat:\n","            self.downs.append(DoubleConv(in_c, f))\n","            in_c = f\n","        # 보틀넥\n","        self.bottleneck = DoubleConv(feat[-1], feat[-1]*2)\n","        # 디코더(Up)\n","        for f in reversed(feat):\n","            self.ups.append(nn.ConvTranspose2d(f*2, f, kernel_size=2, stride=2))\n","            self.ups.append(DoubleConv(f*2, f))\n","        self.final_conv = nn.Conv2d(feat[0], out_c, kernel_size=1)\n","\n","    def forward(self, x):\n","        skips = []\n","        for down in self.downs:\n","            x = down(x)\n","            skips.append(x)\n","            x = F.max_pool2d(x, 2)\n","        x = self.bottleneck(x)\n","        for idx in range(0, len(self.ups), 2):\n","            x = self.ups[idx](x)\n","            skip = skips[-(idx//2 + 1)]\n","            # 크기 불일치 보정 (홀수 입력 대응)\n","            if x.shape != skip.shape:\n","                x = F.pad(x, [0, skip.size(3)-x.size(3), 0, skip.size(2)-x.size(2)])\n","            x = torch.cat([skip, x], dim=1)\n","            x = self.ups[idx+1](x)\n","        return self.final_conv(x)\n","\n","# ==================================================\n","# 5. 손실 & 지표\n","# ==================================================\n","class DiceLoss(nn.Module):\n","    def __init__(self, smooth: float = 1.):\n","        super().__init__()\n","        self.smooth = smooth\n","    def forward(self, logits, targets):\n","        probs = torch.sigmoid(logits)\n","        targets = targets.float()\n","        inter = (probs * targets).sum(dim=[2,3])\n","        union = probs.sum(dim=[2,3]) + targets.sum(dim=[2,3])\n","        dice = (2*inter + self.smooth) / (union + self.smooth)\n","        return 1 - dice.mean()\n","\n","def dice_coef(logits, targets):\n","    probs = (torch.sigmoid(logits) > 0.5).float()\n","    inter = (probs * targets).sum(dim=[1,2,3])\n","    union = probs.sum(dim=[1,2,3]) + targets.sum(dim=[1,2,3])\n","    return (2*inter / (union + 1e-8)).mean().item()\n","\n"],"metadata":{"id":"6TFHHoQRAuec"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 6. train & validate 함수\n","# ==================================================\n","\n","def train_one_epoch(model, loader, opt, loss_fn):\n","    model.train()\n","    tot_loss = tot_dice = 0.\n","    for step, (imgs, masks) in enumerate(loader):\n","        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n","        opt.zero_grad()\n","        logits = model(imgs)\n","        loss = loss_fn(logits, masks) + nn.BCEWithLogitsLoss()(logits, masks)\n","        loss.backward()\n","        opt.step()\n","\n","        tot_loss += loss.item()\n","        tot_dice += dice_coef(logits.detach(), masks)\n","\n","        if (step+1) % PRINT_FREQ == 0:\n","            print(f\"step {step+1}/{len(loader)}  loss {tot_loss/(step+1):.4f}  dice {tot_dice/(step+1):.4f}\")\n","    return tot_loss/len(loader), tot_dice/len(loader)\n","\n","@torch.no_grad()\n","def evaluate(model, loader, loss_fn):\n","    model.eval()\n","    tot_loss = tot_dice = 0.\n","    for imgs, masks in loader:\n","        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n","        logits = model(imgs)\n","        loss = loss_fn(logits, masks) + nn.BCEWithLogitsLoss()(logits, masks)\n","        tot_loss += loss.item()\n","        tot_dice += dice_coef(logits, masks)\n","    return tot_loss/len(loader), tot_dice/len(loader)"],"metadata":{"id":"JP4pcIqXAuhN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 7. 학습 구동\n","# ==================================================\n","model = UNet().to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","loss_fn   = DiceLoss()\n","\n","best_dice, best_path = 0., \"best_unet.pth\"\n","\n","for epoch in range(EPOCHS):\n","    print(f\"\\n===== Epoch {epoch+1}/{EPOCHS} =====\")\n","    tr_loss, tr_dice = train_one_epoch(model, train_loader, optimizer, loss_fn)\n","    val_loss, val_dice = evaluate(model, val_loader, loss_fn)\n","    print(f\"Train loss {tr_loss:.4f} dice {tr_dice:.4f} │ Val loss {val_loss:.4f} dice {val_dice:.4f}\")\n","\n","    if val_dice > best_dice:\n","        best_dice = val_dice\n","        torch.save(model.state_dict(), best_path)\n","        print(f\"  ▶ 모델 갱신! (dice={best_dice:.4f})\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hOxA6aVVv8Uv","executionInfo":{"status":"ok","timestamp":1745722166103,"user_tz":-540,"elapsed":3447361,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"397261f0-79c5-42ad-95bf-28f6f3f67213"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["총 1258개 이미지/마스크 쌍 로드 완료\n","\n","===== Epoch 1/100 =====\n","Train loss 1.4132 dice 0.1065 │ Val loss 1.8663 dice 0.0855\n","  ▶ 모델 갱신! (dice=0.0855)\n","\n","===== Epoch 2/100 =====\n","Train loss 1.2850 dice 0.0996 │ Val loss 1.2517 dice 0.0696\n","\n","===== Epoch 3/100 =====\n","Train loss 1.2472 dice 0.1207 │ Val loss 1.2386 dice 0.0950\n","  ▶ 모델 갱신! (dice=0.0950)\n","\n","===== Epoch 4/100 =====\n","Train loss 1.2119 dice 0.1649 │ Val loss 1.1932 dice 0.1813\n","  ▶ 모델 갱신! (dice=0.1813)\n","\n","===== Epoch 5/100 =====\n","Train loss 1.1789 dice 0.2329 │ Val loss 1.1676 dice 0.2230\n","  ▶ 모델 갱신! (dice=0.2230)\n","\n","===== Epoch 6/100 =====\n","Train loss 1.1648 dice 0.2293 │ Val loss 1.1335 dice 0.2441\n","  ▶ 모델 갱신! (dice=0.2441)\n","\n","===== Epoch 7/100 =====\n","Train loss 1.1387 dice 0.2687 │ Val loss 1.1236 dice 0.1670\n","\n","===== Epoch 8/100 =====\n","Train loss 1.1337 dice 0.2553 │ Val loss 1.2203 dice 0.2346\n","\n","===== Epoch 9/100 =====\n","Train loss 1.1234 dice 0.2704 │ Val loss 1.1414 dice 0.2784\n","  ▶ 모델 갱신! (dice=0.2784)\n","\n","===== Epoch 10/100 =====\n","Train loss 1.0773 dice 0.3104 │ Val loss 1.0678 dice 0.2996\n","  ▶ 모델 갱신! (dice=0.2996)\n","\n","===== Epoch 11/100 =====\n","Train loss 1.0617 dice 0.3190 │ Val loss 1.1647 dice 0.2834\n","\n","===== Epoch 12/100 =====\n","Train loss 1.0372 dice 0.3442 │ Val loss 1.0275 dice 0.3123\n","  ▶ 모델 갱신! (dice=0.3123)\n","\n","===== Epoch 13/100 =====\n","Train loss 1.0114 dice 0.3659 │ Val loss 1.0704 dice 0.3409\n","  ▶ 모델 갱신! (dice=0.3409)\n","\n","===== Epoch 14/100 =====\n","Train loss 0.9900 dice 0.3751 │ Val loss 1.0232 dice 0.3514\n","  ▶ 모델 갱신! (dice=0.3514)\n","\n","===== Epoch 15/100 =====\n","Train loss 0.9783 dice 0.3851 │ Val loss 0.9954 dice 0.3404\n","\n","===== Epoch 16/100 =====\n","Train loss 0.9473 dice 0.4198 │ Val loss 0.9721 dice 0.3846\n","  ▶ 모델 갱신! (dice=0.3846)\n","\n","===== Epoch 17/100 =====\n","Train loss 0.9445 dice 0.4089 │ Val loss 1.0746 dice 0.3302\n","\n","===== Epoch 18/100 =====\n","Train loss 0.9275 dice 0.4156 │ Val loss 1.0290 dice 0.3191\n","\n","===== Epoch 19/100 =====\n","Train loss 0.8957 dice 0.4503 │ Val loss 0.9203 dice 0.4376\n","  ▶ 모델 갱신! (dice=0.4376)\n","\n","===== Epoch 20/100 =====\n","Train loss 0.8737 dice 0.4641 │ Val loss 0.8821 dice 0.4432\n","  ▶ 모델 갱신! (dice=0.4432)\n","\n","===== Epoch 21/100 =====\n","Train loss 0.8655 dice 0.4627 │ Val loss 0.8747 dice 0.4878\n","  ▶ 모델 갱신! (dice=0.4878)\n","\n","===== Epoch 22/100 =====\n","Train loss 0.8372 dice 0.4983 │ Val loss 0.8879 dice 0.4125\n","\n","===== Epoch 23/100 =====\n","Train loss 0.8218 dice 0.5064 │ Val loss 0.8609 dice 0.4809\n","\n","===== Epoch 24/100 =====\n","Train loss 0.8037 dice 0.5154 │ Val loss 0.8293 dice 0.4729\n","\n","===== Epoch 25/100 =====\n","Train loss 0.7809 dice 0.5317 │ Val loss 0.8898 dice 0.4306\n","\n","===== Epoch 26/100 =====\n","Train loss 0.7688 dice 0.5349 │ Val loss 0.8067 dice 0.5116\n","  ▶ 모델 갱신! (dice=0.5116)\n","\n","===== Epoch 27/100 =====\n","Train loss 0.7450 dice 0.5553 │ Val loss 0.8019 dice 0.5120\n","  ▶ 모델 갱신! (dice=0.5120)\n","\n","===== Epoch 28/100 =====\n","Train loss 0.7345 dice 0.5603 │ Val loss 0.7790 dice 0.5139\n","  ▶ 모델 갱신! (dice=0.5139)\n","\n","===== Epoch 29/100 =====\n","Train loss 0.7286 dice 0.5532 │ Val loss 0.7684 dice 0.5147\n","  ▶ 모델 갱신! (dice=0.5147)\n","\n","===== Epoch 30/100 =====\n","Train loss 0.7056 dice 0.5690 │ Val loss 0.7675 dice 0.5049\n","\n","===== Epoch 31/100 =====\n","Train loss 0.6994 dice 0.5641 │ Val loss 0.7308 dice 0.5371\n","  ▶ 모델 갱신! (dice=0.5371)\n","\n","===== Epoch 32/100 =====\n","Train loss 0.7026 dice 0.5684 │ Val loss 0.7728 dice 0.4570\n","\n","===== Epoch 33/100 =====\n","Train loss 0.6709 dice 0.5838 │ Val loss 0.7207 dice 0.5637\n","  ▶ 모델 갱신! (dice=0.5637)\n","\n","===== Epoch 34/100 =====\n","Train loss 0.6398 dice 0.6105 │ Val loss 0.7187 dice 0.5323\n","\n","===== Epoch 35/100 =====\n","Train loss 0.6266 dice 0.6156 │ Val loss 0.7154 dice 0.5315\n","\n","===== Epoch 36/100 =====\n","Train loss 0.6183 dice 0.6189 │ Val loss 0.6674 dice 0.5823\n","  ▶ 모델 갱신! (dice=0.5823)\n","\n","===== Epoch 37/100 =====\n","Train loss 0.6031 dice 0.6263 │ Val loss 0.6710 dice 0.5658\n","\n","===== Epoch 38/100 =====\n","Train loss 0.5794 dice 0.6445 │ Val loss 0.6675 dice 0.5609\n","\n","===== Epoch 39/100 =====\n","Train loss 0.5582 dice 0.6618 │ Val loss 0.6219 dice 0.6044\n","  ▶ 모델 갱신! (dice=0.6044)\n","\n","===== Epoch 40/100 =====\n","Train loss 0.5624 dice 0.6523 │ Val loss 0.7101 dice 0.4908\n","\n","===== Epoch 41/100 =====\n","Train loss 0.5394 dice 0.6660 │ Val loss 0.6210 dice 0.5888\n","\n","===== Epoch 42/100 =====\n","Train loss 0.5362 dice 0.6654 │ Val loss 0.6169 dice 0.5840\n","\n","===== Epoch 43/100 =====\n","Train loss 0.5243 dice 0.6694 │ Val loss 0.6735 dice 0.5071\n","\n","===== Epoch 44/100 =====\n","Train loss 0.4973 dice 0.6885 │ Val loss 0.6152 dice 0.5903\n","\n","===== Epoch 45/100 =====\n","Train loss 0.4826 dice 0.6974 │ Val loss 0.6041 dice 0.5770\n","\n","===== Epoch 46/100 =====\n","Train loss 0.4768 dice 0.7018 │ Val loss 0.6149 dice 0.5621\n","\n","===== Epoch 47/100 =====\n","Train loss 0.4676 dice 0.7104 │ Val loss 0.5763 dice 0.6018\n","\n","===== Epoch 48/100 =====\n","Train loss 0.4642 dice 0.7095 │ Val loss 0.6187 dice 0.5401\n","\n","===== Epoch 49/100 =====\n","Train loss 0.4657 dice 0.7044 │ Val loss 0.5938 dice 0.5771\n","\n","===== Epoch 50/100 =====\n","Train loss 0.4392 dice 0.7211 │ Val loss 0.5560 dice 0.6019\n","\n","===== Epoch 51/100 =====\n","Train loss 0.4198 dice 0.7323 │ Val loss 0.5223 dice 0.6313\n","  ▶ 모델 갱신! (dice=0.6313)\n","\n","===== Epoch 52/100 =====\n","Train loss 0.4221 dice 0.7212 │ Val loss 0.5434 dice 0.6160\n","\n","===== Epoch 53/100 =====\n","Train loss 0.3861 dice 0.7583 │ Val loss 0.5126 dice 0.6412\n","  ▶ 모델 갱신! (dice=0.6412)\n","\n","===== Epoch 54/100 =====\n","Train loss 0.3742 dice 0.7600 │ Val loss 0.5240 dice 0.6233\n","\n","===== Epoch 55/100 =====\n","Train loss 0.3854 dice 0.7495 │ Val loss 0.4923 dice 0.6538\n","  ▶ 모델 갱신! (dice=0.6538)\n","\n","===== Epoch 56/100 =====\n","Train loss 0.3473 dice 0.7780 │ Val loss 0.5020 dice 0.6376\n","\n","===== Epoch 57/100 =====\n","Train loss 0.3535 dice 0.7706 │ Val loss 0.5071 dice 0.6246\n","\n","===== Epoch 58/100 =====\n","Train loss 0.3494 dice 0.7712 │ Val loss 0.5412 dice 0.6043\n","\n","===== Epoch 59/100 =====\n","Train loss 0.3236 dice 0.7881 │ Val loss 0.4801 dice 0.6485\n","\n","===== Epoch 60/100 =====\n","Train loss 0.3238 dice 0.7832 │ Val loss 0.4809 dice 0.6391\n","\n","===== Epoch 61/100 =====\n","Train loss 0.3064 dice 0.7961 │ Val loss 0.4835 dice 0.6350\n","\n","===== Epoch 62/100 =====\n","Train loss 0.3065 dice 0.7918 │ Val loss 0.5326 dice 0.5892\n","\n","===== Epoch 63/100 =====\n","Train loss 0.3026 dice 0.7945 │ Val loss 0.5127 dice 0.5963\n","\n","===== Epoch 64/100 =====\n","Train loss 0.2840 dice 0.8062 │ Val loss 0.4902 dice 0.6202\n","\n","===== Epoch 65/100 =====\n","Train loss 0.2816 dice 0.8079 │ Val loss 0.4561 dice 0.6509\n","\n","===== Epoch 66/100 =====\n","Train loss 0.2647 dice 0.8196 │ Val loss 0.4791 dice 0.6225\n","\n","===== Epoch 67/100 =====\n","Train loss 0.2479 dice 0.8320 │ Val loss 0.4527 dice 0.6530\n","\n","===== Epoch 68/100 =====\n","Train loss 0.2555 dice 0.8241 │ Val loss 0.4644 dice 0.6435\n","\n","===== Epoch 69/100 =====\n","Train loss 0.2346 dice 0.8392 │ Val loss 0.4655 dice 0.6347\n","\n","===== Epoch 70/100 =====\n","Train loss 0.2267 dice 0.8450 │ Val loss 0.4530 dice 0.6483\n","\n","===== Epoch 71/100 =====\n","Train loss 0.2358 dice 0.8335 │ Val loss 0.4851 dice 0.6114\n","\n","===== Epoch 72/100 =====\n","Train loss 0.2254 dice 0.8405 │ Val loss 0.4277 dice 0.6653\n","  ▶ 모델 갱신! (dice=0.6653)\n","\n","===== Epoch 73/100 =====\n","Train loss 0.2045 dice 0.8578 │ Val loss 0.4396 dice 0.6499\n","\n","===== Epoch 74/100 =====\n","Train loss 0.1956 dice 0.8649 │ Val loss 0.4666 dice 0.6273\n","\n","===== Epoch 75/100 =====\n","Train loss 0.1978 dice 0.8623 │ Val loss 0.4380 dice 0.6483\n","\n","===== Epoch 76/100 =====\n","Train loss 0.1812 dice 0.8754 │ Val loss 0.4298 dice 0.6617\n","\n","===== Epoch 77/100 =====\n","Train loss 0.1818 dice 0.8742 │ Val loss 0.4647 dice 0.6218\n","\n","===== Epoch 78/100 =====\n","Train loss 0.2354 dice 0.8373 │ Val loss 0.4568 dice 0.6446\n","\n","===== Epoch 79/100 =====\n","Train loss 0.2502 dice 0.8166 │ Val loss 0.5658 dice 0.5477\n","\n","===== Epoch 80/100 =====\n","Train loss 0.2514 dice 0.8137 │ Val loss 0.4663 dice 0.6329\n","\n","===== Epoch 81/100 =====\n","Train loss 0.2192 dice 0.8375 │ Val loss 0.4393 dice 0.6501\n","\n","===== Epoch 82/100 =====\n","Train loss 0.1963 dice 0.8583 │ Val loss 0.4246 dice 0.6599\n","\n","===== Epoch 83/100 =====\n","Train loss 0.1871 dice 0.8633 │ Val loss 0.4569 dice 0.6296\n","\n","===== Epoch 84/100 =====\n","Train loss 0.1742 dice 0.8743 │ Val loss 0.4392 dice 0.6463\n","\n","===== Epoch 85/100 =====\n","Train loss 0.1679 dice 0.8792 │ Val loss 0.4030 dice 0.6766\n","  ▶ 모델 갱신! (dice=0.6766)\n","\n","===== Epoch 86/100 =====\n","Train loss 0.1652 dice 0.8808 │ Val loss 0.4271 dice 0.6573\n","\n","===== Epoch 87/100 =====\n","Train loss 0.1572 dice 0.8877 │ Val loss 0.4189 dice 0.6623\n","\n","===== Epoch 88/100 =====\n","Train loss 0.1436 dice 0.8981 │ Val loss 0.4239 dice 0.6586\n","\n","===== Epoch 89/100 =====\n","Train loss 0.1424 dice 0.8988 │ Val loss 0.4221 dice 0.6587\n","\n","===== Epoch 90/100 =====\n","Train loss 0.1388 dice 0.9005 │ Val loss 0.4801 dice 0.6163\n","\n","===== Epoch 91/100 =====\n","Train loss 0.1329 dice 0.9054 │ Val loss 0.4294 dice 0.6525\n","\n","===== Epoch 92/100 =====\n","Train loss 0.1250 dice 0.9107 │ Val loss 0.4169 dice 0.6611\n","\n","===== Epoch 93/100 =====\n","Train loss 0.1189 dice 0.9158 │ Val loss 0.4072 dice 0.6688\n","\n","===== Epoch 94/100 =====\n","Train loss 0.1202 dice 0.9140 │ Val loss 0.4045 dice 0.6712\n","\n","===== Epoch 95/100 =====\n","Train loss 0.1225 dice 0.9114 │ Val loss 0.4309 dice 0.6472\n","\n","===== Epoch 96/100 =====\n","Train loss 0.1165 dice 0.9167 │ Val loss 0.4232 dice 0.6552\n","\n","===== Epoch 97/100 =====\n","Train loss 0.1154 dice 0.9166 │ Val loss 0.4257 dice 0.6575\n","\n","===== Epoch 98/100 =====\n","Train loss 0.1141 dice 0.9174 │ Val loss 0.4196 dice 0.6591\n","\n","===== Epoch 99/100 =====\n","Train loss 0.1158 dice 0.9153 │ Val loss 0.4025 dice 0.6741\n","\n","===== Epoch 100/100 =====\n","Train loss 0.1133 dice 0.9177 │ Val loss 0.3972 dice 0.6772\n","  ▶ 모델 갱신! (dice=0.6772)\n"]}]},{"cell_type":"code","source":["# ==================================================\n","# ★ 세그멘테이션 오버레이 시각화 (배치 크기 무관)\n","# ==================================================\n","\n","@torch.no_grad()\n","def visualize_overlay(model, loader, device=DEVICE, n=6, alpha=0.45):\n","    \"\"\"\n","    • 원본 이미지 위에 GT(녹색) · 예측(빨간색) 마스크를 반투명 오버레이\n","    • n 장이 확보될 때까지 DataLoader에서 연속적으로 가져옴\n","    • 최대 4장씩 가로로 배치\n","    \"\"\"\n","    model.eval()\n","\n","    # ---------- n장 모으기 ----------\n","    imgs_acc, masks_acc, preds_acc = [], [], []\n","    for imgs, masks in loader:\n","        imgs_acc.append(imgs)\n","        masks_acc.append(masks)\n","        preds_acc.append((torch.sigmoid(model(imgs.to(device))) > 0.5).cpu())\n","        if sum(b.size(0) for b in imgs_acc) >= n:\n","            break\n","\n","    imgs  = torch.cat(imgs_acc)[:n]   # (n,3,H,W)\n","    masks = torch.cat(masks_acc)[:n]  # (n,1,H,W)\n","    preds = torch.cat(preds_acc)[:n]  # (n,1,H,W)\n","\n","    # ---------- 오버레이 ----------\n","    gt_color   = np.array([0, 1, 0])   # green\n","    pred_color = np.array([1, 0, 0])   # red\n","\n","    cols = 4\n","    rows = math.ceil(n / cols)\n","    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))\n","    axes = axes.flatten()        # 2D → 1D 배열로 편하게 인덱싱\n","\n","    for i in range(n):\n","        img_np = imgs[i].permute(1, 2, 0).numpy()\n","        gt_np  = masks[i, 0].numpy()\n","        pr_np  = preds[i, 0].numpy()\n","\n","        overlay = img_np.copy()\n","        overlay[gt_np == 1] = (1 - alpha) * overlay[gt_np == 1] + alpha * gt_color\n","        overlay[pr_np == 1] = (1 - alpha) * overlay[pr_np == 1] + alpha * pred_color\n","\n","        axes[i].imshow(overlay)\n","        axes[i].axis(\"off\")\n","        axes[i].set_title(f\"Sample {i}\")\n","\n","    # 남는 서브플롯은 비우기\n","    for j in range(n, rows * cols):\n","        axes[j].axis(\"off\")\n","\n","    # 범례\n","    green_patch = mpatches.Patch(color=\"green\", label=\"Ground Truth\")\n","    red_patch   = mpatches.Patch(color=\"red\",   label=\"Prediction\")\n","    plt.legend(handles=[green_patch, red_patch],\n","               bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"wS2ZP9PjwWwf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Best 모델 로드 후 오버레이 시각화\n","model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n","visualize_overlay(model, val_loader, n=16, alpha=0.4)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1tK4fv8zIoYfnviJ3gNvSwBbwmOTlpoEH"},"id":"YN8P7w5ix4Xx","executionInfo":{"status":"ok","timestamp":1745722171584,"user_tz":-540,"elapsed":5474,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"883a11f8-99d8-4834-c176-692c255f6629"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"E1hWhw_hyzZj"},"execution_count":null,"outputs":[]}]}