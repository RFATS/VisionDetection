{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20883,"status":"ok","timestamp":1752155141914,"user":{"displayName":"Junseop So (ÏèòÏ£ºÌòï)","userId":"07758510494740838877"},"user_tz":-540},"id":"HyCiqD8RZbEO","outputId":"f831a834-8124-44ed-972e-ec5871ec733e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10939,"status":"ok","timestamp":1752155152854,"user":{"displayName":"Junseop So (ÏèòÏ£ºÌòï)","userId":"07758510494740838877"},"user_tz":-540},"id":"G47eftO7-h8n","outputId":"c6d1c391-de97-4019-994e-8a5bdc9aecf6"},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ device: cuda\n"]}],"source":["ROOT_DIR  = '/content/drive/MyDrive/Data/MVTecAD'  # Îç∞Ïù¥ÌÑ∞ÏÖã ÏÉÅÏúÑ Í≤ΩÎ°ú\n","SAVE_NAME = f'best_skipgan.pt'\n","\n","# =============================================================\n","# 0.  ÏùòÏ°¥ÏÑ± \u0026 Ï†ÑÏó≠ ÏÑ§Ï†ï\n","# =============================================================\n","import os, random, time\n","from glob   import glob\n","from pathlib import Path\n","import numpy as np, matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","\n","import torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as T\n","from sklearn.metrics import roc_auc_score\n","from torch.nn.utils import spectral_norm\n","import torch.autograd as autograd\n","\n","IMG_SIZE   = 256\n","BATCH_SIZE = 16\n","EPOCHS     = 50\n","LR_G, LR_D = 1e-4, 1e-5\n","BETAS = (0.5, 0.999)\n","lambda_GP = 0.0 #spectral norm\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('‚úÖ device:', DEVICE)\n","\n","# =============================================================\n","# 1.  Îç∞Ïù¥ÌÑ∞ÏÖã \u0026 DataLoader\n","# =============================================================\n","class MVTecADMulti(Dataset):\n","    \"\"\"\n","    Ï†ÑÏ≤¥ Ïπ¥ÌÖåÍ≥†Î¶¨(train/good, test/good + defects)Î•º Ìïú Î≤àÏóê Ïä§Ï∫î\n","      ¬∑ phase='train' ‚Üí Î™®Îì† */train/good   (label=0)\n","      ¬∑ phase='test'  ‚Üí */test/good          (label=0)\n","                        */test/\u003cdefect\u003e/*    (label=1)\n","    \"\"\"\n","    def __init__(self, root_dir:str, phase:str='train'):\n","        assert phase in ('train', 'test')\n","        self.phase = phase\n","        self.paths = []          # (img_path, label)\n","\n","        for cat in sorted(os.listdir(root_dir)):\n","            cat_path = Path(root_dir)/cat\n","            if not cat_path.is_dir():\n","                continue\n","\n","            if phase == 'train':\n","                self.paths += [(p,0) for p in\n","                               glob(str(cat_path/'train'/'good'/'*.png'))]\n","            else:   # test\n","                self.paths += [(p,0) for p in\n","                               glob(str(cat_path/'test'/'good'/'*.png'))]\n","                for defect in os.listdir(cat_path/'test'):\n","                    if defect == 'good': continue\n","                    self.paths += [(p,1) for p in\n","                                   glob(str(cat_path/'test'/defect/'*.png'))]\n","\n","        self.tf = T.Compose([\n","            T.ToPILImage(),\n","            T.Resize((IMG_SIZE, IMG_SIZE)),\n","            T.ToTensor(),\n","            T.Normalize([0.5]*3, [0.5]*3)\n","        ])\n","\n","    def __len__(self): return len(self.paths)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.paths[idx]\n","        img = plt.imread(img_path)\n","        if img.ndim == 2:                     # grayscale ‚Üí 3-ch\n","            img = np.stack([img]*3, -1)\n","        if img.max() \u003c= 1:                    # [0,1] ‚Üí [0,255]\n","            img = (img*255).astype(np.uint8)\n","        return self.tf(img), label\n","\n","\n","def get_loaders_all(root_dir):\n","    train_ds = MVTecADMulti(root_dir, 'train')\n","    test_ds  = MVTecADMulti(root_dir, 'test')\n","\n","    train_loader = DataLoader(\n","        train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n","\n","    test_loader  = DataLoader(\n","        test_ds, batch_size=BATCH_SIZE, shuffle=True)\n","\n","    return train_loader, test_loader\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1752155152865,"user":{"displayName":"Junseop So (ÏèòÏ£ºÌòï)","userId":"07758510494740838877"},"user_tz":-540},"id":"U9XgiEjn-HMU"},"outputs":[],"source":["# =============================================================\n","# 2.  ÎÑ§Ìä∏ÏõåÌÅ¨ Ï†ïÏùò (Skip-GANomaly)\n","# =============================================================\n","# ------------------------------------------------\n","# Í≥µÌÜµ Ï¥àÍ∏∞Ìôî Ìï®Ïàò\n","# ------------------------------------------------\n","def weights_init(m):\n","    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n","        nn.init.normal_(m.weight, 0.0, 0.02)\n","        if m.bias is not None:\n","            nn.init.zeros_(m.bias)\n","\n","# ------------------------------------------------\n","# Generator  (Skip-GANomaly)\n","# ------------------------------------------------\n","class DownBlock(nn.Module):\n","    \"\"\"Conv(stride=2) ‚Üí BN ‚Üí LeakyReLU\"\"\"\n","    def __init__(self, c_in, c_out):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Conv2d(c_in, c_out, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(c_out),\n","            nn.LeakyReLU(0.2),\n","        )\n","    def forward(self, x): return self.net(x)\n","\n","class UpBlock(nn.Module):\n","    \"\"\"ConvTranspose(stride=2) ‚Üí BN ‚Üí ReLU\"\"\"\n","    def __init__(self, c_in, c_out):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.ConvTranspose2d(c_in, c_out, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(c_out),\n","            nn.ReLU(),\n","        )\n","    def forward(self, x): return self.net(x)\n","\n","class Generator(nn.Module):\n","    \"\"\"\n","    ‚Ä¢ Ïù∏ÏΩîÎçî  : 3‚Üí64‚Üí128‚Üí256‚Üí512 (4-Ïä§ÌÉ≠)\n","    ‚Ä¢ ÎîîÏΩîÎçî  : 512‚Üí256‚Üí128‚Üí64 (3-Ïä§ÌÉ≠) + ÏµúÏ¢Ö Conv\n","    ‚Ä¢ skip Ïó∞Í≤∞: ÎèôÏùº Ìï¥ÏÉÅÎèÑ Î†àÏù¥Ïñ¥ÎÅºÎ¶¨ concat\n","    \"\"\"\n","    def __init__(self, base=64):\n","        super().__init__()\n","        # ---- Encoder ----\n","        self.e1 = DownBlock(3,      base)         # 256 ‚Üí 128\n","        self.e2 = DownBlock(base,   base*2)       # 128 ‚Üí 64\n","        self.e3 = DownBlock(base*2, base*4)       #  64 ‚Üí 32\n","        self.e4 = DownBlock(base*4, base*8)       #  32 ‚Üí 16\n","\n","        # ---- Bottleneck ----  (stride-1 conv Îëê Î≤à)\n","        self.bottle = nn.Sequential(\n","            nn.Conv2d(base*8, base*8, 3, 1, 1, bias=False),\n","            nn.ReLU(),\n","            nn.Conv2d(base*8, base*8, 3, 1, 1, bias=False),\n","            nn.ReLU(),\n","        )\n","\n","        # ---- Decoder ----\n","        self.d3 = UpBlock(base*8,   base*4)       # 16 ‚Üí 32\n","        self.d2 = UpBlock(base*8,   base*2)       # 32 ‚Üí 64   (skip concat)\n","        self.d1 = UpBlock(base*4,   base)         # 64 ‚Üí 128  (skip concat)\n","\n","        # ---- Output (Î≥µÏõê Ïù¥ÎØ∏ÏßÄ) ----\n","        self.out_conv = nn.Sequential(\n","            nn.ConvTranspose2d(base*2, 3, 4, 2, 1, bias=False),  # 128 ‚Üí 256\n","            nn.Tanh(),\n","        )\n","\n","        self.apply(weights_init)\n","\n","    def forward(self, x):\n","        # Encoder\n","        e1 = self.e1(x)\n","        e2 = self.e2(e1)\n","        e3 = self.e3(e2)\n","        e4 = self.e4(e3)\n","\n","        # Bottleneck\n","        b  = self.bottle(e4)\n","\n","        # Decoder + skip\n","        d3 = self.d3(b)              # 16‚Üí32\n","        d3 = torch.cat([d3, e3], 1)  # 256 + 256 = 512\n","\n","        d2 = self.d2(d3)             # 32‚Üí64\n","        d2 = torch.cat([d2, e2], 1)  # 128 + 128 = 256\n","\n","        d1 = self.d1(d2)             # 64‚Üí128\n","        d1 = torch.cat([d1, e1], 1)  # 64 + 64 = 128\n","\n","        out = self.out_conv(d1)      # 128‚Üí256\n","        return out                   # [-1,1] Î≤îÏúÑ (tanh)\n","\n","# ------------------------------------------------\n","# Discriminator  (PatchGAN + Feature extraction)\n","# ------------------------------------------------\n","class Discriminator(nn.Module):\n","    \"\"\"\n","    ‚Ä¢ Conv stride-2 Î•º 5Îã® ÏåìÏïÑ 16√ó16 Ìå®Ïπò Îã®ÏúÑ ÌåêÎ≥Ñ (256 ÏûÖÎ†• Í∏∞Ï§Ä)\n","    ‚Ä¢ WGAN GP / LSGAN Îì± Ïñ¥Îñ§ GAN Î°úÏä§ÏóêÎèÑ Î∞îÎ°ú ÏÇ¨Ïö© Í∞ÄÎä•\n","    ‚Ä¢ return_feat=True Ïãú encoder stage ÌèâÍ∑†Í∞íÏùÑ concat ‚Üí feature vector\n","    \"\"\"\n","    def __init__(self, base=64):\n","        super().__init__()\n","        def dblk(c_in, c_out, bn=True):\n","            layers = [spectral_norm(nn.Conv2d(c_in, c_out, 4, 2, 1, bias=False))]\n","            if bn: layers.append(nn.BatchNorm2d(c_out))\n","            layers.append(nn.LeakyReLU(0.2, inplace=True))\n","            return nn.Sequential(*layers)\n","\n","        self.stem = nn.Sequential(\n","            dblk(3,      base,   bn=False),  # 256 ‚Üí 128\n","            dblk(base,   base*2),            # 128 ‚Üí 64\n","            dblk(base*2, base*4),            # 64  ‚Üí 32\n","            dblk(base*4, base*8),            # 32  ‚Üí 16\n","            dblk(base*8, base*8),            # 16  ‚Üí 8\n","        )\n","        self.out_conv = spectral_norm(nn.Conv2d(base*8, 1, 4, 1, 0))  # 8‚Üí1\n","\n","        self.apply(weights_init)\n","\n","    def forward(self, x, return_feat=False):\n","        feats = []\n","        h = x\n","        for layer in self.stem:\n","            h = layer(h)\n","            feats.append(h)\n","\n","        score = self.out_conv(h).view(-1)   # PatchGAN: (B)\n","        if return_feat:\n","            # Í∞Å stage feature map ÌèâÍ∑† ‚Üí concat (Skip-GANomaly lossÏö©)\n","            fvec = torch.cat([f.mean([2, 3]) for f in feats], dim=1)\n","            return score, fvec\n","        return score"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1752155152873,"user":{"displayName":"Junseop So (ÏèòÏ£ºÌòï)","userId":"07758510494740838877"},"user_tz":-540},"id":"8VFtsWq7auab"},"outputs":[],"source":["# =============================================================\n","# 3.  ÌïôÏäµ Î£®ÌîÑ \u0026 ÌèâÍ∞Ä Ìï®Ïàò\n","# =============================================================\n","L_adv, L_rec, L_fm = nn.BCEWithLogitsLoss(), nn.L1Loss(), nn.L1Loss()\n","\n","def gradient_penalty(D, real, fake):\n","    Œ± = torch.rand(real.size(0),1,1,1, device=real.device)\n","    inter = (Œ±*real + (1-Œ±)*fake).requires_grad_(True)\n","    score = D(inter)\n","    grad  = autograd.grad(outputs=score, inputs=inter,\n","                          grad_outputs=torch.ones_like(score),\n","                          create_graph=True, retain_graph=True)[0]\n","    gp = ((grad.view(grad.size(0), -1).norm(2, dim=1) - 1)**2).mean()\n","    return gp\n","\n","def train_epoch(G,D,loader,optG,optD,lambda_rec=50,lambda_fm=10):\n","    G.train(); D.train(); g_tot=d_tot=0\n","    for imgs,_ in tqdm(loader, leave=False):\n","        imgs = imgs.to(DEVICE)\n","\n","        # --- D (maximize real-fake gap) ---\n","        optD.zero_grad()\n","        fake = G(imgs).detach()\n","        d_real = D(imgs)\n","        d_fake = D(fake)\n","        gp = gradient_penalty(D, imgs, fake)\n","        d_loss = -(d_real.mean() - d_fake.mean()) + lambda_GP*gp\n","        d_loss.backward(); optD.step()\n","\n","        # --- G (fool D + recon + feature-match) ---\n","        optG.zero_grad()\n","        fake = G(imgs)\n","        g_adv = -D(fake).mean()                     # WGAN generator loss\n","        _, feat_f = D(fake, True)\n","        _, feat_r = D(imgs, True)\n","        g_rec = L_rec(fake, imgs)\n","        g_fm  = L_fm(feat_f, feat_r.detach())\n","        g_loss = g_adv + lambda_rec*g_rec + lambda_fm*g_fm\n","        g_loss.backward(); optG.step()\n","\n","        g_tot += g_loss.item();  d_tot += d_loss.item()\n","    n=len(loader); return g_tot/n, d_tot/n\n","    return g_tot/n, d_tot/n\n","\n","@torch.inference_mode()\n","def get_scores(G, loader):\n","    G.eval(); scores=[]; labels=[]\n","    for imgs,lbl in loader:\n","        imgs = imgs.to(DEVICE)\n","        err  = torch.mean((G(imgs) - imgs).abs(), dim=[1,2,3])\n","        scores += err.cpu().tolist(); labels += lbl\n","    return np.array(scores), np.array(labels)\n","\n","def fit_all(root_dir, save_path):\n","    tl, vl = get_loaders_all(root_dir)   # ‚Üê cat Ïù∏Ïàò Ï†úÍ±∞\n","    G, D = Generator().to(DEVICE), Discriminator().to(DEVICE)\n","    optG = torch.optim.Adam(G.parameters(), LR_G, betas=BETAS)\n","    optD = torch.optim.Adam(D.parameters(), LR_D, betas=BETAS)\n","    best_auc = 0\n","    for ep in range(1, EPOCHS+1):\n","        g, d = train_epoch(G, D, tl, optG, optD)\n","        s, l = get_scores(G, vl);  auc = roc_auc_score(l, s)\n","        if auc \u003e best_auc:\n","            best_auc = auc;  torch.save(G.state_dict(), save_path)\n","        print(f'[Ep {ep:03d}] G:{g:.3f}  D:{d:.3f}  AUC:{auc:.4f} (best {best_auc:.4f})')\n","    print('üèÅ Done! best AUC:', best_auc)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":0},"id":"9yRgx1HEaw8z"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebd854ccd27544658a12f3196df5235e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/226 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# =============================================================\n","# 4.  ÌïôÏäµ Ïã§Ìñâ\n","# =============================================================\n","SAVE_NAME = 'best_skipgan_all.pt'\n","fit_all(ROOT_DIR, SAVE_NAME)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Nhi1-4y9PJ5"},"outputs":[],"source":["# =============================================================\n","# 5.  Ïû¨Íµ¨ÏÑ± ÏãúÍ∞ÅÌôî (ÌïôÏäµ ÌõÑ)\n","# =============================================================\n","SAVE_NAME = '/content/best_skipgan_all.pt'\n","\n","@torch.inference_mode()\n","def show_recon(G, loader, n=6):\n","    G.eval()\n","    imgs,_ = next(iter(loader)); imgs = imgs[:n].to(DEVICE)\n","    recon = G(imgs)\n","    imgs, recon = imgs.cpu()*0.5+0.5, recon.cpu()*0.5+0.5\n","    plt.figure(figsize=(n*2,4))\n","    for i in range(n):\n","        plt.subplot(2,n,i+1);     plt.imshow(imgs[i].permute(1,2,0));   plt.axis('off')\n","        plt.subplot(2,n,n+i+1);   plt.imshow(recon[i].permute(1,2,0));  plt.axis('off')\n","    plt.suptitle('Input (top) vs Reconstruction (bottom)'); plt.show()\n","\n","# ÏÇ¨Ïö© Ïòà\n","G = Generator().to(DEVICE); G.load_state_dict(torch.load(SAVE_NAME))\n","_, test_loader = get_loaders_all(ROOT_DIR)\n","show_recon(G, test_loader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MlUAxFn3Bi_9"},"outputs":[],"source":["# Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏóê ÎåÄÌï¥ Ï†ïÏÉÅ/Ïù¥ÏÉÅ Í∞úÏàò ÌôïÏù∏\n","num_norm = sum(1 for _, y in test_loader.dataset if y == 0)\n","num_anom = sum(1 for _, y in test_loader.dataset if y == 1)\n","print(f\"‚úî Ï†ïÏÉÅ(good)   : {num_norm:,}\")\n","print(f\"‚úî Ïù¥ÏÉÅ(defect) : {num_anom:,}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CwbN5iW0CqAt"},"outputs":[],"source":["# =============================================================\n","# 6.  ÌÖåÏä§Ìä∏ \u0026 ÏãúÍ∞ÅÌôî  (G ¬∑ SAVE_NAME Î°ú Î≥ÄÏàò ÎßûÏ∂§)\n","# =============================================================\n","import torch.nn.functional as F\n","\n","# ‚ë† Generator Ïù∏Ïä§ÌÑ¥Ïä§ Ï§ÄÎπÑ \u0026 Í∞ÄÏ§ëÏπò Î°úÎìú\n","G = Generator().to(DEVICE)\n","G.load_state_dict(torch.load(SAVE_NAME, map_location=DEVICE))\n","G.eval()\n","\n","errs, labels, paths = [], [], []\n","idx_global = 0                                   # paths Ïù∏Îç±Ïä§ Í≥ÑÏÇ∞Ïö©\n","\n","with torch.no_grad():\n","    for imgs, lbls in test_loader:               # (img, label)\n","        bsz      = imgs.size(0)\n","        imgs_gpu = imgs.to(DEVICE)\n","        recons   = G(imgs_gpu)\n","\n","        err = F.mse_loss(recons, imgs_gpu, reduction='none')\n","        err = err.flatten(1).mean(1).cpu().numpy()\n","\n","        errs.append(err)\n","        labels.append(lbls.numpy())\n","\n","        batch_paths = [test_loader.dataset.paths[idx_global + i][0]\n","                       for i in range(bsz)]\n","        paths += batch_paths\n","        idx_global += bsz\n","\n","errs   = np.concatenate(errs)\n","labels = np.concatenate(labels)\n","\n","# 95-percentile ÏûÑÍ≥ÑÍ∞í\n","THRESH = np.percentile(errs[labels == 0], 95)\n","\n","# ---------- (1) ÏóêÎü¨ Î∂ÑÌè¨ ----------\n","hist_n, edges = np.histogram(errs[labels == 0], bins=60)\n","hist_a, _     = np.histogram(errs[labels == 1], bins=edges)\n","centers       = (edges[:-1] + edges[1:]) / 2\n","\n","plt.figure(figsize=(7,4))\n","plt.bar(centers, hist_n, width=centers[1]-centers[0], label='Normal',  alpha=.6)\n","plt.bar(centers, hist_a, width=centers[1]-centers[0], label='Anomaly', alpha=.6)\n","plt.axvline(THRESH, ls='--', lw=2, color='k', label=f'Thresh={THRESH:.4f}')\n","plt.xlabel('Reconstruction MSE'); plt.ylabel('Count')\n","plt.title ('Error distribution (test)'); plt.legend()\n","plt.tight_layout(); plt.show()\n","\n","# ---------- (2) Ï†ïÏÉÅ¬∑Ïù¥ÏÉÅ ÏòàÏãú ----------\n","def pick_idxs(labels, errs, thresh, n_each=5):\n","    idx_norm = np.where((labels == 0) \u0026 (errs \u003c thresh))[0][:n_each]\n","    idx_anom = np.where((labels == 1) \u0026 (errs \u003e thresh))[0][:n_each]\n","    return np.concatenate([idx_norm, idx_anom])\n","\n","sel = pick_idxs(labels, errs, THRESH, 5)\n","\n","fig, axes = plt.subplots(2, 5, figsize=(15,6))\n","for i, ax in enumerate(axes.flatten()):\n","    img = plt.imread(paths[sel[i]])[..., :3]\n","    ax.imshow(img); ax.axis('off')\n","    ax.set_title(f\"{'Normal' if i \u003c 5 else 'Anomaly'}\\nMSE={errs[sel[i]]:.4f}\")\n","plt.suptitle('Reconstruction-based Anomaly Detection')\n","plt.tight_layout(); plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O0CAqCFZ-5ki"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMTjca+vKfVP69oWHDYeiEp","gpuType":"L4","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1b141bd4f4e7489e9b2e6f115c0ca3f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d2d42faec4e47e09c748919b5e3d9d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46e67e4393ed4b078f19716fda03a542":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f614646b1fb64bb2ab688fece0e32fcc","placeholder":"‚Äã","style":"IPY_MODEL_1b141bd4f4e7489e9b2e6f115c0ca3f7","value":"‚Äá‚Äá0%"}},"4bd9f05746ef44d38e62b46f033a525d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"772a0dcaaf2f4d23a58244aac8ba1ef3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"943506ec9f934a6699593ff8372d0c34":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8c67adeb8d742808ca7cd484122afad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c982e105de524c369a1ec5fefb45a75b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_943506ec9f934a6699593ff8372d0c34","max":226,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8c67adeb8d742808ca7cd484122afad","value":0}},"e828c880a16b4486901b45b9b5e2ebd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d2d42faec4e47e09c748919b5e3d9d7","placeholder":"‚Äã","style":"IPY_MODEL_4bd9f05746ef44d38e62b46f033a525d","value":"‚Äá0/226‚Äá[00:00\u0026lt;?,‚Äá?it/s]"}},"ebd854ccd27544658a12f3196df5235e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46e67e4393ed4b078f19716fda03a542","IPY_MODEL_c982e105de524c369a1ec5fefb45a75b","IPY_MODEL_e828c880a16b4486901b45b9b5e2ebd5"],"layout":"IPY_MODEL_772a0dcaaf2f4d23a58244aac8ba1ef3"}},"f614646b1fb64bb2ab688fece0e32fcc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}