{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RFATS/VisionDetection/blob/exam/3.%20Projects/Final%20Project_answer/%5BFinal%20Project%5D%201.%20MVTecAD%20Classification_answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HyCiqD8RZbEO",
        "outputId": "b34462f4-fe4f-411c-bb69-f94448a29198",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.cpu_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26Xi5RbE40sH",
        "outputId": "aa57ae11-fa7b-4bf6-89d6-a46f17aaf917"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 0. 의존성 & 전역 설정\n",
        "# ==================================================\n",
        "import os, random, time\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch, torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------\n",
        "# 사용자 하이퍼파라미터\n",
        "# ------------------------------\n",
        "ROOT_DIR   = \"/content/drive/MyDrive/Data/MVTecAD\"  # 데이터셋 경로\n",
        "IMG_SIZE   = 224\n",
        "BATCH_SIZE = 32\n",
        "VAL_RATIO  = 0.2\n",
        "EPOCHS     = 10\n",
        "LR         = 1e-4\n",
        "BEST_PATH  = \"best_model.pt\"\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 시드 고정\n",
        "# --------------------------------------------------\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"✅ 사용 디바이스:\", DEVICE)\n"
      ],
      "metadata": {
        "id": "Y67UcNDKwb-v",
        "outputId": "02181480-82c2-43e3-fc3b-c93ee7143db1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 사용 디바이스: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 1. Dataset (mask 제외 + 3채널 변환)\n",
        "# ==================================================\n",
        "class MVTecClsDataset(Dataset):\n",
        "    \"\"\"MVTecAD 전체 구조(train+test)를 한 번에 스캔해\n",
        "    `category_defect` 단위 클래스로 만드는 Dataset.\n",
        "    • train/ 하위는 항상 `good` 이므로 라벨 = f\"{category}_good\"\n",
        "    • test/ 하위는 결함 폴더(예: broken_large)를 그대로 라벨에 사용\n",
        "    • 파일명에 `mask` 포함 시 제외\n",
        "    • 모든 이미지는 3채널(RGB)로 강제 변환\n",
        "    \"\"\"\n",
        "\n",
        "    VALID_EXT = {\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\"}\n",
        "    HIDDEN    = {\".ipynb_checkpoints\", \".DS_Store\"}\n",
        "\n",
        "    def __init__(self, root_dir: str, transforms=None):\n",
        "        self.root = Path(root_dir)\n",
        "        self.t    = transforms\n",
        "        self.samples: List[Tuple[Path, int]] = []\n",
        "        self.classes: List[str] = []\n",
        "        self._scan()\n",
        "\n",
        "    def _scan(self):\n",
        "        lbl2idx = {}\n",
        "        for p in self.root.rglob(\"*\"):\n",
        "            # --- 유효 파일 필터 ---\n",
        "            if not (p.is_file() and p.suffix.lower() in self.VALID_EXT):\n",
        "                continue\n",
        "            if any(h in p.parts for h in self.HIDDEN):\n",
        "                continue\n",
        "            if \"mask\" in p.stem.lower():\n",
        "                continue\n",
        "            parts = p.relative_to(self.root).parts  # (category, train/test, defect?, img)\n",
        "            if len(parts) < 3:\n",
        "                continue\n",
        "            category, phase = parts[0], parts[1]\n",
        "            defect = \"good\" if phase == \"train\" else parts[2]\n",
        "            lbl_name = f\"{category}_{defect}\"\n",
        "            cls_idx = lbl2idx.setdefault(lbl_name, len(lbl2idx))\n",
        "            self.samples.append((p, cls_idx))\n",
        "\n",
        "        self.classes = [lbl for lbl, _ in sorted(lbl2idx.items(), key=lambda kv: kv[1])]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        p, label = self.samples[idx]\n",
        "        img = torchvision.io.read_image(str(p)).float() / 255.0\n",
        "        if img.shape[0] == 1:\n",
        "            img = img.repeat(3, 1, 1)\n",
        "        elif img.shape[0] == 4:\n",
        "            img = img[:3]\n",
        "        if self.t:\n",
        "            img = self.t(img)\n",
        "        return img, label, str(p)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YJCCPsonbtCl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 2. DataLoader\n",
        "# ==================================================\n",
        "train_tfms = T.Compose([T.Resize((IMG_SIZE,IMG_SIZE)), T.RandomHorizontalFlip(), T.RandomRotation(10)])\n",
        "val_tfms = T.Resize((IMG_SIZE,IMG_SIZE))\n",
        "\n",
        "base_ds = MVTecClsDataset(ROOT_DIR)\n",
        "indices = list(range(len(base_ds)))\n",
        "random.shuffle(indices)\n",
        "val_len = int(len(indices)*VAL_RATIO)\n",
        "val_idx,train_idx = indices[:val_len],indices[val_len:]\n",
        "train_set, val_set = Subset(base_ds, train_idx), Subset(base_ds, val_idx)\n",
        "\n",
        "make_loader = lambda ds,tfm,shuf: DataLoader(ds,batch_size=BATCH_SIZE,shuffle=shuf,\n",
        "                                             num_workers=2 if torch.cuda.is_available() else 0,\n",
        "                                             pin_memory=torch.cuda.is_available(),\n",
        "                                             collate_fn=lambda b:(torch.stack([tfm(x[0]) for x in b]),\n",
        "                                                                torch.tensor([x[1] for x in b]),\n",
        "                                                                [x[2] for x in b]))\n",
        "train_loader = make_loader(train_set,train_tfms,True)\n",
        "val_loader = make_loader(val_set,val_tfms,False)\n",
        "idx2lbl=base_ds.classes\n",
        "print(\"클래스:\", idx2lbl)\n",
        "\n"
      ],
      "metadata": {
        "id": "oIXwcWQnbtFZ",
        "outputId": "3eb92e42-e861-49cc-bada-887360286b04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스: ['leather_color', 'leather_poke', 'leather_glue', 'leather_good', 'leather_fold', 'leather_cut', 'cable_missing_wire', 'cable_cut_outer_insulation', 'cable_good', 'cable_bent_wire', 'cable_cable_swap', 'cable_poke_insulation', 'cable_missing_cable', 'cable_combined', 'cable_cut_inner_insulation', 'capsule_good', 'capsule_crack', 'capsule_scratch', 'capsule_poke', 'capsule_faulty_imprint', 'capsule_squeeze', 'hazelnut_good', 'hazelnut_print', 'hazelnut_crack', 'hazelnut_hole', 'hazelnut_cut', 'bottle_broken_large', 'bottle_broken_small', 'bottle_contamination', 'bottle_good', 'carpet_color', 'carpet_metal_contamination', 'carpet_good', 'carpet_thread', 'carpet_cut', 'carpet_hole', 'metal_nut_color', 'metal_nut_good', 'metal_nut_scratch', 'metal_nut_bent', 'metal_nut_flip', 'screw_good', 'screw_scratch_neck', 'screw_scratch_head', 'screw_thread_top', 'screw_manipulated_front', 'screw_thread_side', 'pill_crack', 'pill_pill_type', 'pill_scratch', 'pill_color', 'pill_good', 'pill_faulty_imprint', 'pill_combined', 'pill_contamination', 'grid_good', 'grid_bent', 'grid_metal_contamination', 'grid_broken', 'grid_glue', 'grid_thread', 'transistor_damaged_case', 'transistor_misplaced', 'transistor_cut_lead', 'transistor_good', 'transistor_bent_lead', 'tile_rough', 'tile_crack', 'tile_good', 'tile_gray_stroke', 'tile_glue_strip', 'tile_oil', 'toothbrush_defective', 'toothbrush_good', 'zipper_split_teeth', 'zipper_broken_teeth', 'zipper_fabric_interior', 'zipper_rough', 'zipper_squeezed_teeth', 'zipper_combined', 'zipper_fabric_border', 'zipper_good', 'wood_color', 'wood_liquid', 'wood_combined', 'wood_hole', 'wood_scratch', 'wood_good']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 3. 모델 정의\n",
        "# ==================================================\n",
        "# pretrained EfficientNet B0 사용\n",
        "model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
        "\n",
        "# 분류기 헤드 교체\n",
        "num_classes = len(idx2lbl)\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.2, inplace=True),\n",
        "    nn.Linear(in_features=1280, out_features=num_classes)\n",
        ")\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "vq7H8NerbtIa",
        "outputId": "13576767-9a9e-4b7d-f9c5-19f2fd61a9f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 144MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 4. 학습 루프\n",
        "# ==================================================\n",
        "best_acc = 0\n",
        "train_losses, val_losses = [], []\n",
        "train_accs, val_accs = [], []\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # ---- Train ----\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for imgs, labels, _ in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\"):\n",
        "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * imgs.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "    train_acc = correct / total\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "    # ---- Validate ----\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for imgs, labels, _ in tqdm(val_loader, desc=\"Validating\"):\n",
        "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * imgs.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    val_acc = correct / total\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    # 스케줄러 & 최적 모델 저장\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), BEST_PATH)\n",
        "        print(f\"✓ 모델 저장됨: {BEST_PATH} (acc={best_acc:.4f})\")\n",
        "\n",
        "    print(f\"Epoch {epoch}/{EPOCHS} - \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "# 학습 결과 시각화\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Val Loss')\n",
        "plt.title('Loss per Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accs, label='Train Acc')\n",
        "plt.plot(val_accs, label='Val Acc')\n",
        "plt.title('Accuracy per Epoch')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 최적 모델 로드\n",
        "model.load_state_dict(torch.load(BEST_PATH))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "fhlPh978btLY",
        "outputId": "f381e8f7-6a99-42d1-84f2-b3d14ed4eaae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:  57%|█████▋    | 77/134 [13:15<11:10, 11.76s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 5. 시각화 (파란=정답, 빨간=오답)\n",
        "# ==================================================\n",
        "# 검증 배치 GT vs 예측 (색상 구분)\n",
        "model.eval(); val_imgs,val_labels, _ = next(iter(val_loader))\n",
        "with torch.inference_mode(): preds = model(val_imgs.to(DEVICE)).argmax(1).cpu()\n",
        "plt.figure(figsize=(16,4))\n",
        "for i in range(8):\n",
        "    correct=preds[i]==val_labels[i]; color='blue' if correct else 'red'\n",
        "    plt.subplot(2,4,i+1)\n",
        "    plt.imshow(val_imgs[i].permute(1,2,0))\n",
        "    plt.title(f\"GT:{idx2lbl[int(val_labels[i])]}\\nPR:{idx2lbl[int(preds[i])]}\", color=color)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "WUk5dvNyvqkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VxCbgHAWyZOm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}