{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HyCiqD8RZbEO"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G47eftO7-h8n"},"outputs":[],"source":["ROOT_DIR  = '/content/drive/MyDrive/Data/MVTecAD'  # 데이터셋 상위 경로\n","SAVE_NAME = f'best_skipgan.pt'\n","\n","# =============================================================\n","# 0.  의존성 & 전역 설정\n","# =============================================================\n","import os, random, time\n","from glob   import glob\n","from pathlib import Path\n","import numpy as np, matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","import copy\n","\n","import torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as T\n","from sklearn.metrics import roc_auc_score\n","from torch.nn.utils import spectral_norm\n","import torch.autograd as autograd\n","\n","IMG_SIZE   = 256\n","BATCH_SIZE = 16\n","EPOCHS     = #TODO\n","LR_G, LR_D = #TODO\n","BETAS = (0.5, 0.999)\n","lambda_GP = 0.0 #spectral norm\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('✅ device:', DEVICE)\n","\n","# =============================================================\n","# 1.  데이터셋 & DataLoader\n","# =============================================================\n","class MVTecADMulti(Dataset):\n","    \"\"\"\n","    지정한 카테고리만 스캔하도록 수정됨\n","      · phase='train' → bottle/train/good   (label=0)\n","      · phase='test'  → bottle/test/good      (label=0)\n","                        bottle/test/<defect>/*(label=1)\n","    \"\"\"\n","    def __init__(self, root_dir:str, phase:str='train'):\n","        assert phase in ('train', 'test')\n","        self.phase = phase\n","        self.paths = []  # (img_path, label)\n","\n","        # 'bottle' 카테고리 경로만 직접 지정\n","        cat_path = Path(root_dir) / 'bottle'\n","\n","        if not cat_path.is_dir():\n","            # 'bottle' 폴더가 없을 경우 오류 발생\n","            raise FileNotFoundError(f\"지정된 경로에 'bottle' 폴더가 없습니다: {cat_path}\")\n","\n","        if phase == 'train':\n","            # 훈련 데이터: 정상(good) 샘플만 로드\n","            self.paths += [(p, 0) for p in glob(str(cat_path / 'train' / 'good' / '*.png'))]\n","        else:  # 'test'\n","            # 테스트 데이터: 정상(good) 샘플 로드\n","            self.paths += [(p, 0) for p in glob(str(cat_path / 'test' / 'good' / '*.png'))]\n","            # 테스트 데이터: 비정상(defect) 샘플들 로드\n","            for defect in os.listdir(cat_path / 'test'):\n","                if defect == 'good':\n","                    continue\n","                defect_path = cat_path / 'test' / defect\n","                self.paths += [(p, 1) for p in glob(str(defect_path / '*.png'))]\n","\n","        self.tf = T.Compose([\n","            T.ToPILImage(),\n","            T.Resize((IMG_SIZE, IMG_SIZE)),\n","            T.ToTensor(),\n","            T.Normalize([0.5] * 3, [0.5] * 3)\n","        ])\n","\n","    def __len__(self):\n","        return len(self.paths)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.paths[idx]\n","        img = plt.imread(img_path)\n","        if img.ndim == 2:  # grayscale → 3-ch\n","            img = np.stack([img] * 3, -1)\n","        if img.max() <= 1:  # [0,1] → [0,255]\n","            img = (img * 255).astype(np.uint8)\n","        # ❗ [수정] 이미지 경로를 함께 반환\n","        return self.tf(img), label, img_path\n","\n","\n","def get_loaders_all(root_dir):\n","    train_ds = MVTecADMulti(root_dir, 'train')\n","    test_ds  = MVTecADMulti(root_dir, 'test')\n","\n","    train_loader = DataLoader(\n","        train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n","\n","    # ❗ [수정] 테스트 시에는 데이터를 섞지 않도록 shuffle=False로 변경\n","    test_loader  = DataLoader(\n","        test_ds, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    return train_loader, test_loader\n","\n"]},{"cell_type":"code","source":["# =============================================================\n","# 2.  네트워크 정의 (Skip-GANomaly)\n","# =============================================================\n","#TODO"],"metadata":{"id":"U9XgiEjn-HMU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =============================================================\n","# 3.  학습 루프 & 평가 함수\n","# =============================================================\n","L_adv, L_rec, L_fm = nn.BCEWithLogitsLoss(), nn.L1Loss(), nn.L1Loss()\n","\n","def gradient_penalty(D, real, fake):\n","    a_weights = torch.rand(real.size(0),1,1,1, device=real.device)\n","    inter = (a_weights*real + (1-a_weights)*fake).requires_grad_(True)\n","    score = D(inter)\n","    grad  = autograd.grad(outputs=score, inputs=inter,\n","                          grad_outputs=torch.ones_like(score),\n","                          create_graph=True, retain_graph=True)[0]\n","    gp = ((grad.view(grad.size(0), -1).norm(2, dim=1) - 1)**2).mean()\n","    return gp\n","\n","def train_epoch(G,D,loader,optG,optD,lambda_rec=50,lambda_fm=10):\n","    G.train(); D.train(); g_tot=d_tot=0\n","    for imgs, _, _ in tqdm(loader, leave=False):\n","        imgs = imgs.to(DEVICE)\n","\n","        # --- D (maximize real-fake gap) ---\n","        optD.zero_grad()\n","        fake = G(imgs).detach()\n","        d_real = D(imgs)\n","        d_fake = D(fake)\n","        gp = gradient_penalty(D, imgs, fake)\n","        d_loss = -(d_real.mean() - d_fake.mean()) + lambda_GP*gp\n","        d_loss.backward(); optD.step()\n","\n","        # --- G (fool D + recon + feature-match) ---\n","        optG.zero_grad()\n","        fake = G(imgs)\n","        g_adv = -D(fake).mean()                     # WGAN generator loss\n","        _, feat_f = D(fake, True)\n","        _, feat_r = D(imgs, True)\n","        g_rec = L_rec(fake, imgs)\n","        g_fm  = L_fm(feat_f, feat_r.detach())\n","        g_loss = g_adv + lambda_rec*g_rec + lambda_fm*g_fm\n","        g_loss.backward(); optG.step()\n","\n","        g_tot += g_loss.item();  d_tot += d_loss.item()\n","    n=len(loader); return g_tot/n, d_tot/n\n","\n","@torch.inference_mode()\n","def get_scores(G, loader):\n","    G.eval(); scores=[]; labels=[]\n","    for imgs, lbl, _ in loader:\n","        imgs = imgs.to(DEVICE)\n","        err  = torch.mean((G(imgs) - imgs).abs(), dim=[1,2,3])\n","        scores += err.cpu().tolist(); labels += lbl\n","    return np.array(scores), np.array(labels)\n","\n","def fit_all(root_dir, save_path_g, save_path_d):\n","    \"\"\"\n","    모델을 학습하고, 가장 성능이 좋았던 시점의\n","    Generator(G)와 Discriminator(D) 모델 객체를 반환합니다.\n","    \"\"\"\n","    tl, vl = get_loaders_all(root_dir)\n","    G, D = Generator().to(DEVICE), Discriminator().to(DEVICE)\n","    optG = torch.optim.Adam(G.parameters(), LR_G, betas=BETAS)\n","    optD = torch.optim.Adam(D.parameters(), LR_D, betas=BETAS)\n","\n","    best_auc = 0\n","    best_G_state = None\n","    best_D_state = None # [추가] 최고 성능 D의 가중치를 저장할 변수\n","\n","    for ep in range(1, EPOCHS+1):\n","        g, d = train_epoch(G, D, tl, optG, optD)\n","        s, l = get_scores(G, vl)\n","        auc = roc_auc_score(l, s)\n","\n","        if auc > best_auc:\n","            best_auc = auc\n","            # [수정] G와 D의 가중치를 함께 저장\n","            best_G_state = copy.deepcopy(G.state_dict())\n","            best_D_state = copy.deepcopy(D.state_dict())\n","            torch.save(best_G_state, save_path_g)\n","            torch.save(best_D_state, save_path_d)\n","\n","        print(f'[Ep {ep:03d}] G:{g:.3f}  D:{d:.3f}  AUC:{auc:.4f} (best {best_auc:.4f})')\n","\n","    print(f'\\nDone! best AUC: {best_auc:.4f}')\n","\n","    # [수정] G와 D 모두에 최고 성능 가중치를 로드\n","    if best_G_state and best_D_state:\n","        G.load_state_dict(best_G_state)\n","        D.load_state_dict(best_D_state)\n","\n","    # [수정] G와 D 모델 객체를 모두 반환\n","    return G, D\n"],"metadata":{"id":"8VFtsWq7auab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =============================================================\n","# 4.  학습 실행\n","# =============================================================\n","\n","# G와 D의 저장 경로를 각각 정의합니다.\n","G_SAVE_NAME = 'best_skipgan_all.pt'\n","D_SAVE_NAME = 'best_skipgan_all_D.pt'\n","\n","# 2개의 저장 경로를 모두 인자로 전달합니다.\n","best_G, best_D = fit_all(ROOT_DIR, G_SAVE_NAME, D_SAVE_NAME)"],"metadata":{"id":"9yRgx1HEaw8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# =============================================================\n","# 5.  재구성 시각화 (학습 후)\n","# =============================================================\n","SAVE_NAME = '/content/best_skipgan_all.pt'\n","\n","@torch.inference_mode()\n","def show_recon(G, loader, n=6):\n","    G.eval()\n","    imgs, _, _ = next(iter(loader))\n","    imgs = imgs[:n].to(DEVICE)\n","\n","    recon = G(imgs)\n","    imgs, recon = imgs.cpu()*0.5+0.5, recon.cpu()*0.5+0.5\n","    plt.figure(figsize=(n*2,4))\n","    for i in range(n):\n","        plt.subplot(2,n,i+1);     plt.imshow(imgs[i].permute(1,2,0));   plt.axis('off')\n","        plt.subplot(2,n,n+i+1);   plt.imshow(recon[i].permute(1,2,0));  plt.axis('off')\n","    plt.suptitle('Input (top) vs Reconstruction (bottom)'); plt.show()\n","\n","# 💡 사용 예: 파일 로드 과정 없이, 위에서 반환받은 `best_G_model`을 즉시 사용\n","_, test_loader = get_loaders_all(ROOT_DIR)\n","show_recon(best_G, test_loader)\n","\n","# 전체 데이터셋에 대해 정상/이상 개수 확인\n","num_norm = sum(1 for _, y, _ in test_loader.dataset if y == 0)\n","num_anom = sum(1 for _, y, _ in test_loader.dataset if y == 1)\n","print(f\"✔ 정상(good)   : {num_norm:,}\")\n","print(f\"✔ 이상(defect) : {num_anom:,}\")"],"metadata":{"id":"6Nhi1-4y9PJ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 전체 데이터셋에 대해 정상/이상 개수 확인\n","num_norm = sum(1 for path, label in test_loader.dataset.paths if label == 0)\n","num_anom = sum(1 for path, label in test_loader.dataset.paths if label == 1)\n","print(f\"✔ 정상(good)   : {num_norm:,}\")\n","print(f\"✔ 이상(defect) : {num_anom:,}\")\n"],"metadata":{"id":"MlUAxFn3Bi_9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CwbN5iW0CqAt"},"outputs":[],"source":["# =============================================================\n","# 6.  테스트 & 시각화\n","# =============================================================\n","import torch.nn.functional as F\n","\n","# ❗ [수정] 파일 로드 블록 전체를 삭제하고,\n","# 이전 단계에서 반환받은 모델 객체를 즉시 사용합니다.\n","best_G.eval()\n","best_D.eval()\n","\n","# Anomaly Score 계산을 위한 가중치 (lambda)\n","LAMBDA_SCORE = 0.1\n","\n","# ② 테스트 데이터셋 전체에 대해 Anomaly Score 계산\n","scores, labels, paths = [], [], []\n","with torch.no_grad():\n","    # test_loader는 미리 로드되어 있어야 합니다.\n","    _, test_loader = get_loaders_all(ROOT_DIR)\n","\n","    for imgs, lbls, batch_paths in tqdm(test_loader, 'Testing'):\n","        imgs_gpu = imgs.to(DEVICE)\n","\n","        # 1. 재구성 이미지 생성 (best_G 사용)\n","        recons = best_G(imgs_gpu)\n","\n","        # 2. 재구성 오차 (L_con) 계산: |x - G(x)|\n","        err_rec = torch.mean(torch.abs(imgs_gpu - recons), dim=[1,2,3])\n","\n","        # 3. 판별자 특징 추출 (best_D 사용)\n","        _, feat_real = best_D(imgs_gpu, return_feat=True)\n","        _, feat_fake = best_D(recons, return_feat=True)\n","\n","        # 4. 특징 공간 오차 (L_enc) 계산: |f_D(x) - f_D(G(x))|\n","        err_enc = torch.mean(torch.abs(feat_real - feat_fake), dim=1)\n","\n","        # 5. 최종 이상치 점수 계산\n","        batch_scores = (1 - LAMBDA_SCORE) * err_rec + LAMBDA_SCORE * err_enc\n","\n","        scores.append(batch_scores.cpu().numpy())\n","        labels.append(lbls.numpy())\n","        paths += batch_paths\n","\n","scores = np.concatenate(scores)\n","labels = np.concatenate(labels)\n","\n","\n","# ③ 결과를 바탕으로 시각화 (이하 로직은 동일)\n","# 정상 데이터의 점수 분포에서 95% 지점을 임계값으로 설정\n","THRESH = np.percentile(scores[labels == 0], 95)\n","\n","# ---------- (1) 점수 분포 시각화 ----------\n","hist_n, edges = np.histogram(scores[labels == 0], bins=60, range=(scores.min(), scores.max()))\n","hist_a, _     = np.histogram(scores[labels == 1], bins=edges)\n","centers       = (edges[:-1] + edges[1:]) / 2\n","bar_width     = centers[1] - centers[0]\n","\n","plt.figure(figsize=(8, 5))\n","plt.bar(centers, hist_n, width=bar_width, label='Normal',  alpha=.7)\n","plt.bar(centers, hist_a, width=bar_width, label='Anomaly', alpha=.7, bottom=hist_n)\n","plt.axvline(THRESH, ls='--', lw=2, color='k', label=f'Threshold={THRESH:.4f}')\n","plt.xlabel('Anomaly Score'); plt.ylabel('Count')\n","plt.title ('Anomaly Score Distribution (Test Set)'); plt.legend()\n","plt.tight_layout(); plt.show()\n","\n","\n","# ---------- (2) 정상·이상 판별 예시 시각화 ----------\n","def pick_idxs(labels, scores, thresh, n_each=5):\n","    # 정상으로 판별된 정상 샘플 (True Negative)\n","    idx_norm = np.where((labels == 0) & (scores < thresh))[0]\n","    # 이상으로 판별된 이상 샘플 (True Positive)\n","    idx_anom = np.where((labels == 1) & (scores > thresh))[0]\n","\n","    # 각 그룹에서 n_each개씩 랜덤으로 선택\n","    # 샘플 수가 부족할 경우를 대비해 replace=True 설정\n","    sel_norm = np.random.choice(idx_norm, n_each, replace=len(idx_norm) < n_each)\n","    sel_anom = np.random.choice(idx_anom, n_each, replace=len(idx_anom) < n_each)\n","\n","    return np.concatenate([sel_norm, sel_anom])\n","\n","# 시각화할 샘플 인덱스 선택\n","sel_indices = pick_idxs(labels, scores, THRESH, 5)\n","\n","fig, axes = plt.subplots(2, 5, figsize=(15, 6.5))\n","axes = axes.flatten()\n","for i, idx in enumerate(sel_indices):\n","    img = plt.imread(paths[idx])[..., :3]\n","    ax = axes[i]\n","    ax.imshow(img)\n","    ax.axis('off')\n","\n","    # 앞 5개는 Normal, 뒤 5개는 Anomaly\n","    label_str = 'Normal (TN)' if i < 5 else 'Anomaly (TP)'\n","    ax.set_title(f\"{label_str}\\nScore={scores[idx]:.4f}\")\n","\n","plt.suptitle('Anomaly Detection Examples (Correct Predictions)')\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","plt.show()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"O0CAqCFZ-5ki"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMulE5aGZf287AsDSs/yTgN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}