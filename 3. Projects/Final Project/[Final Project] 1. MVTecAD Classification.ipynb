{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HyCiqD8RZbEO"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","os.cpu_count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26Xi5RbE40sH","executionInfo":{"status":"ok","timestamp":1745885556500,"user_tz":-540,"elapsed":3,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"d3e25369-757e-486c-9598-8e2ea992c1b5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","loader = DataLoader(\n","    dataset, # 데이터셋\n","    batch_size=32,\n","    shuffle=True,\n","    num_workers=os.cpu_count(),   # Colab: 2~4 vCPU → 2-4 권장\n","    pin_memory=torch.cuda.is_available(),\n","    prefetch_factor=4,            # 초당 3-4배치 이상 사전 로드\n","    persistent_workers=True,      # epoch 간 워커 재사용\n",")"],"metadata":{"id":"izIEN7yc4ysq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 0. 의존성 & 전역 설정\n","# ==================================================\n","import os, random, time\n","from pathlib import Path\n","from typing import List, Tuple\n","\n","import torch, torchvision\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","import torchvision.transforms as T\n","from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","# ------------------------------\n","# 사용자 하이퍼파라미터\n","# ------------------------------\n","ROOT_DIR   = \"/content/drive/MyDrive/Data/MVTecAD\"  # 데이터셋 경로\n","IMG_SIZE   = 224\n","BATCH_SIZE = 32\n","VAL_RATIO  = 0.2\n","EPOCHS     = 10\n","LR         = 1e-4\n","BEST_PATH  = \"best_model.pt\"\n","\n","# --------------------------------------------------\n","# 시드 고정\n","# --------------------------------------------------\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"✅ 사용 디바이스:\", DEVICE)\n"],"metadata":{"id":"Y67UcNDKwb-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 1. Dataset (mask 제외 + 3채널 변환)\n","# ==================================================\n","class MVTecClsDataset(Dataset):\n","    \"\"\"MVTecAD 전체 구조(train+test)를 한 번에 스캔해\n","    `category_defect` 단위 클래스로 만드는 Dataset.\n","    • train/ 하위는 항상 `good` 이므로 라벨 = f\"{category}_good\"\n","    • test/ 하위는 결함 폴더(예: broken_large)를 그대로 라벨에 사용\n","    • 파일명에 `mask` 포함 시 제외\n","    • 모든 이미지는 3채널(RGB)로 강제 변환\n","    \"\"\"\n","\n","    VALID_EXT = {\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\"}\n","    HIDDEN    = {\".ipynb_checkpoints\", \".DS_Store\"}\n","\n","    def __init__(self, root_dir: str, transforms=None):\n","        self.root = Path(root_dir)\n","        self.t    = transforms\n","        self.samples: List[Tuple[Path, int]] = []\n","        self.classes: List[str] = []\n","        self._scan()\n","\n","    def _scan(self):\n","        lbl2idx = {}\n","        for p in self.root.rglob(\"*\"):\n","            # --- 유효 파일 필터 ---\n","            if not (p.is_file() and p.suffix.lower() in self.VALID_EXT):\n","                continue\n","            if any(h in p.parts for h in self.HIDDEN):\n","                continue\n","            if \"mask\" in p.stem.lower():\n","                continue\n","            parts = p.relative_to(self.root).parts  # (category, train/test, defect?, img)\n","            if len(parts) < 3:\n","                continue\n","            category, phase = parts[0], parts[1]\n","            defect = \"good\" if phase == \"train\" else parts[2]\n","            lbl_name = f\"{category}_{defect}\"\n","            cls_idx = lbl2idx.setdefault(lbl_name, len(lbl2idx))\n","            self.samples.append((p, cls_idx))\n","\n","        self.classes = [lbl for lbl, _ in sorted(lbl2idx.items(), key=lambda kv: kv[1])]\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        p, label = self.samples[idx]\n","        img = torchvision.io.read_image(str(p)).float() / 255.0\n","        if img.shape[0] == 1:\n","            img = img.repeat(3, 1, 1)\n","        elif img.shape[0] == 4:\n","            img = img[:3]\n","        if self.t:\n","            img = self.t(img)\n","        return img, label, str(p)\n","\n","\n"],"metadata":{"id":"YJCCPsonbtCl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 2. DataLoader\n","# ==================================================\n","train_tfms = T.Compose([T.Resize((IMG_SIZE,IMG_SIZE)), T.RandomHorizontalFlip(), T.RandomRotation(10)])\n","val_tfms = T.Resize((IMG_SIZE,IMG_SIZE))\n","\n","base_ds = MVTecClsDataset(ROOT_DIR)\n","indices = list(range(len(base_ds)))\n","random.shuffle(indices)\n","val_len = int(len(indices)*VAL_RATIO)\n","val_idx,train_idx = indices[:val_len],indices[val_len:]\n","train_set, val_set = Subset(base_ds, train_idx), Subset(base_ds, val_idx)\n","\n","make_loader = lambda ds,tfm,shuf: DataLoader(ds,batch_size=BATCH_SIZE,shuffle=shuf,\n","                                             num_workers=2 if torch.cuda.is_available() else 0,\n","                                             pin_memory=torch.cuda.is_available(),\n","                                             collate_fn=lambda b:(torch.stack([tfm(x[0]) for x in b]),\n","                                                                torch.tensor([x[1] for x in b]),\n","                                                                [x[2] for x in b]))\n","train_loader = make_loader(train_set,train_tfms,True)\n","val_loader = make_loader(val_set,val_tfms,False)\n","idx2lbl=base_ds.classes\n","print(\"클래스:\", idx2lbl)\n","\n"],"metadata":{"id":"oIXwcWQnbtFZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 3. 모델 정의\n","# ==================================================\n","# TODO\n"],"metadata":{"id":"vq7H8NerbtIa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 4. 학습 루프\n","# ==================================================\n","# TODO"],"metadata":{"id":"fhlPh978btLY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==================================================\n","# 5. 시각화 (파란=정답, 빨간=오답)\n","# ==================================================\n","# 검증 배치 GT vs 예측 (색상 구분)\n","model.eval(); val_imgs,val_labels, _ = next(iter(val_loader))\n","with torch.inference_mode(): preds = model(val_imgs.to(DEVICE)).argmax(1).cpu()\n","plt.figure(figsize=(16,4))\n","for i in range(8):\n","    correct=preds[i]==val_labels[i]; color='blue' if correct else 'red'\n","    plt.subplot(2,4,i+1)\n","    plt.imshow(val_imgs[i].permute(1,2,0))\n","    plt.title(f\"GT:{idx2lbl[int(val_labels[i])]}\\nPR:{idx2lbl[int(preds[i])]}\", color=color)\n","    plt.axis('off')\n","plt.tight_layout(); plt.show()"],"metadata":{"id":"WUk5dvNyvqkA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VxCbgHAWyZOm"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNSA+OE7kg7uRitgiT1+BKH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}