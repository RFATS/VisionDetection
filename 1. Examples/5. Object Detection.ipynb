{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyOWA4nVY59ixcmjXZjzKhBR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torchvision"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acnppdovh2I1","executionInfo":{"status":"ok","timestamp":1752122788790,"user_tz":-540,"elapsed":74384,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"7818ffb1-b56f-439a-dac6-b20027bb4c35"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fGvyU41eVLKB","executionInfo":{"status":"ok","timestamp":1752122811575,"user_tz":-540,"elapsed":22783,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"e82db73f-e040-45f2-eac9-d8d8d1040e51"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","from torch.utils.data import DataLoader\n","import torchvision\n","from torchvision import transforms\n","from torchvision.datasets import CocoDetection\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.utils import draw_bounding_boxes\n","from torchvision.transforms.functional import to_pil_image\n","from torchvision.ops import nms\n","import matplotlib.pyplot as plt\n","\n","# 1) 환경 설정\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"],"metadata":{"id":"UZlFsY4jdMmw","executionInfo":{"status":"ok","timestamp":1752122820921,"user_tz":-540,"elapsed":9345,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# 2) 데이터 경로\n","img_dir = '/content/drive/MyDrive/Data/CV_dataset/Segmentation/images'           # 이미지가 저장된 폴더\n","ann_file = '/content/drive/MyDrive/Data/CV_dataset/Detection/annotations.json'   # COCO 주석 파일"],"metadata":{"id":"lCy-_SnGdO5X","executionInfo":{"status":"ok","timestamp":1752122820925,"user_tz":-540,"elapsed":2,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# 4) CocoDetection Dataset 래핑\n","class CustomCocoDataset(CocoDetection):\n","    def __init__(self, img_folder, ann_file, transforms=None):\n","        super().__init__(img_folder, ann_file)\n","        self._transforms = transforms\n","\n","    def __getitem__(self, idx):\n","        img, targets = super().__getitem__(idx)\n","        # ─────────────────────────────────────────────────────\n","        # COCO annotation → 모델 입력용 타깃 변환\n","        # ─────────────────────────────────────────────────────\n","        # 1) bbox·label 추출 (COCO 형식: [x_min, y_min, width, height])\n","        boxes_list  = [obj[\"bbox\"]        for obj in targets]   # 예) [[140, 175, 307, 328]]\n","        labels_list = [obj[\"category_id\"] for obj in targets]\n","\n","        # 2) 리스트 → Tensor 변환\n","        boxes = torch.as_tensor(boxes_list, dtype=torch.float32)  # shape = (N, 4)\n","\n","        # 3) 빈 annotation 여부 체크\n","        if boxes.numel() == 0:\n","            # 박스가 하나도 없을 때 : shape을 (0,4)로 맞춰 오류 방지\n","            boxes = boxes.view(0, 4)\n","        else:\n","            # ────────────────────────────────────────────────\n","            # COCO는 [x, y, w, h] 이지만\n","            # Faster R-CNN 등 torchvision 모델은 [x1, y1, x2, y2] 를 기대한다.\n","            #   x2 = x1 + w\n","            #   y2 = y1 + h\n","            # 즉, width·height를 끝점 좌표로 바꿔야 한다.\n","            # 아래 한 줄이 그 변환을 벡터화해 수행:\n","            #   boxes[:, 2] (width)  += boxes[:, 0] (x1)\n","            #   boxes[:, 3] (height) += boxes[:, 1] (y1)\n","            # 결과: [[x1, y1, x1+w, y1+h]]  >>  [[140, 175, 447, 503]]\n","            # ────────────────────────────────────────────────\n","            boxes[:, 2:] += boxes[:, :2]\n","\n","        labels   = torch.as_tensor(labels_list, dtype=torch.int64)\n","        image_id = torch.tensor([idx])\n","\n","        # 면적(area) 계산 (박스가 있을 때만)\n","        if boxes.numel() > 0:\n","            area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n","        else:\n","            area = torch.tensor([], dtype=torch.float32)\n","\n","        iscrowd = torch.zeros((boxes.size(0),), dtype=torch.int64)\n","\n","        target = {\n","            \"boxes\": boxes,          # [x1, y1, x2, y2] 형식\n","            \"labels\": labels,\n","            \"image_id\": image_id,\n","            \"area\": area,\n","            \"iscrowd\": iscrowd,\n","        }\n","\n","        if self._transforms is not None:\n","            img = self._transforms(img)\n","\n","        return img, target\n"],"metadata":{"id":"hz2tH6-_dPzj","executionInfo":{"status":"ok","timestamp":1752122820941,"user_tz":-540,"elapsed":10,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# 5) 데이터로더 생성\n","dataset_train = CustomCocoDataset(img_dir, ann_file, transforms=transforms.ToTensor())\n","dataset_val   = CustomCocoDataset(img_dir, ann_file, transforms=transforms.ToTensor())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JbdKSILXdSIe","executionInfo":{"status":"ok","timestamp":1752122824247,"user_tz":-540,"elapsed":3305,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"4afd8cb5-1fc9-4afa-8f89-91332af193ff"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=3.28s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n"]}]},{"cell_type":"code","source":["data_loader_train = DataLoader(dataset_train, batch_size=4, shuffle=True, num_workers=2, collate_fn=lambda x: tuple(zip(*x)))\n","data_loader_val   = DataLoader(dataset_val,   batch_size=1, shuffle=False, num_workers=2, collate_fn=lambda x: tuple(zip(*x)))"],"metadata":{"id":"6-bbHWKuiCge","executionInfo":{"status":"ok","timestamp":1752122968698,"user_tz":-540,"elapsed":3,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# ────────────────────────────────────────────────────────────────\n","# DataLoader가 미니배치를 만들 때 수행되는 과정\n","# ────────────────────────────────────────────────────────────────\n","# 1) Sampler가 이번 배치에 사용할 인덱스들(ex. [17, 42, 91, 103])을 뽑는다\n","# 2) 각 인덱스에 대해  dataset[idx]  를 호출하여 (img, target) 튜플을 얻는다\n","#       batch = [\n","#           (img_17,  target_17),\n","#           (img_42,  target_42),\n","#           (img_91,  target_91),\n","#           (img_103, target_103)\n","#       ]\n","#    여기서 batch가 곧 collate_fn의 인수 x 로 전달된다.\n","# 3) collate_fn 은 이 리스트를 (imgs, targets) 형태로 풀어 모델에 공급할 수 있게 한다.\n","# ────────────────────────────────────────────────────────────────\n","\n","# collate_fn을 명시적 함수로 정의 (동일 기능의 lambda 버전을 가독성 있게 분리)\n","# def collate_fn(batch):\n","#     \"\"\"\n","#     batch: [(img, target), (img, target), ...]  # DataLoader가 만든 리스트\n","#     반환:  ( (img1, img2, ...), (target1, target2, ...) )\n","#     \"\"\"\n","#     # zip(*batch)  ➜  ( (img1,img2,..), (target1,target2,..) )\n","#     return tuple(zip(*batch))\n","\n","# # DataLoader에 전달 ─ 이미지 4장씩, shuffle=True\n","# data_loader_train = DataLoader(dataset_train,\n","#                                batch_size=4,\n","#                                shuffle=True,\n","#                                num_workers=2,\n","#                                collate_fn=collate_fn)\n","\n","# data_loader_val   = DataLoader(dataset_val,\n","#                                batch_size=4,\n","#                                shuffle=False,\n","#                                num_workers=2,\n","#                                collate_fn=collate_fn)"],"metadata":{"id":"kT-n8Sywjh6S","executionInfo":{"status":"ok","timestamp":1752122824286,"user_tz":-540,"elapsed":1,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["for x in data_loader_train:\n","    print(x)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-5j1vcjEpvak","executionInfo":{"status":"ok","timestamp":1752122868530,"user_tz":-540,"elapsed":1878,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"c3b74c1f-bff5-453c-97ce-3debe971aabe"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["((tensor([[[0.8392, 0.6314, 0.8392,  ..., 0.2824, 0.3569, 0.9765],\n","         [0.9294, 0.6863, 0.6353,  ..., 0.6824, 0.8510, 0.7176],\n","         [0.4078, 0.3373, 0.7765,  ..., 0.2549, 0.6510, 0.8471],\n","         ...,\n","         [0.2824, 0.1843, 0.4824,  ..., 0.2824, 0.4549, 0.7294],\n","         [0.8588, 0.8745, 0.0471,  ..., 0.3490, 0.2941, 0.7804],\n","         [0.5020, 0.4196, 0.7686,  ..., 0.0118, 0.1725, 0.0196]],\n","\n","        [[0.6039, 0.2118, 0.2314,  ..., 0.0706, 1.0000, 0.9373],\n","         [0.4039, 0.5804, 0.3255,  ..., 0.4039, 0.5647, 0.7176],\n","         [0.9412, 0.2431, 0.7412,  ..., 0.1137, 0.4941, 0.5137],\n","         ...,\n","         [0.9451, 0.4824, 0.7373,  ..., 0.2549, 0.1490, 0.4667],\n","         [0.1608, 0.8353, 0.0588,  ..., 0.5490, 0.9961, 0.9882],\n","         [0.5098, 0.5020, 0.5765,  ..., 0.8863, 0.8510, 0.0275]],\n","\n","        [[0.8118, 0.5490, 0.3882,  ..., 0.8588, 0.5176, 0.9020],\n","         [0.3647, 0.5020, 0.3647,  ..., 0.7843, 0.0902, 0.9255],\n","         [0.0706, 0.0863, 0.1804,  ..., 0.3216, 0.2902, 0.8275],\n","         ...,\n","         [0.7922, 0.5098, 0.9529,  ..., 0.6980, 0.0863, 0.8235],\n","         [0.7098, 0.4275, 0.9373,  ..., 0.6510, 0.7098, 0.5725],\n","         [0.3255, 0.4941, 0.2863,  ..., 0.4118, 0.9098, 0.8784]]]),), ({'boxes': tensor([[186.,  52., 256., 181.],\n","        [113.,   0., 183.,  60.],\n","        [  0.,  73.,  67., 164.]]), 'labels': tensor([1, 2, 3]), 'image_id': tensor([29]), 'area': tensor([9030., 4200., 6097.]), 'iscrowd': tensor([0, 0, 0])},))\n"]}]},{"cell_type":"code","source":["# 6) 모델 정의 (사전학습된 Faster R-CNN 불러오기)\n","model = fasterrcnn_resnet50_fpn(pretrained=True) # weights='DEFAULT'\n","\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","num_classes = 4   # background 포함\n","\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","model.to(device)\n","\n","# 7) Optimizer & Scheduler\n","params = [p for p in model.parameters() if p.requires_grad]\n","\n","optimizer = torch.optim.Adam(params, lr=1e-4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6BesWVqIdTh_","executionInfo":{"status":"ok","timestamp":1752122975414,"user_tz":-540,"elapsed":1711,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"9f100691-2651-43ce-a0c9-9418fe02dbfa"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","100%|██████████| 160M/160M [00:00<00:00, 232MB/s]\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mKeI23mkUey0","executionInfo":{"status":"ok","timestamp":1752123628279,"user_tz":-540,"elapsed":328503,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"82014c04-24bc-4b11-cba8-ee56f1e04a3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Epoch 1/10] Train Loss: 0.3105\n","[Epoch 2/10] Train Loss: 0.2775\n","[Epoch 3/10] Train Loss: 0.2567\n","[Epoch 4/10] Train Loss: 0.2244\n","[Epoch 5/10] Train Loss: 0.1758\n","[Epoch 6/10] Train Loss: 0.2203\n","[Epoch 7/10] Train Loss: 0.2954\n","[Epoch 8/10] Train Loss: 0.2158\n","[Epoch 9/10] Train Loss: 0.1392\n","[Epoch 10/10] Train Loss: 0.1585\n","Training finished.\n"]}],"source":["# 8) 학습 루프 (간단한 예제)\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()\n","    for images, targets in data_loader_train:\n","        images = list(img.to(device) for img in images)\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","        losses = sum(loss for loss in loss_dict.values())\n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","\n","    # Validation 스텝 (optional)\n","    model.eval()\n","    # 여기서는 간단히 첫 배치 예측만 수행\n","    with torch.no_grad():\n","        imgs, tgts = next(iter(data_loader_val))\n","        imgs = list(img.to(device) for img in imgs)\n","        outputs = model(imgs)\n","    print(f\"[Epoch {epoch+1}/{num_epochs}] Train Loss: {losses.item():.4f}\")\n","\n","print(\"Training finished.\")\n"]},{"cell_type":"code","source":["# 카테고리 ID → 이름 매핑\n","category_names = {1: \"anomaly_1\", 2: \"anomaly_2\", 3: \"anomaly_3\"}\n","\n","model.eval()\n","images, targets = next(iter(data_loader_val))\n","images = [img.to(device) for img in images]\n","\n","with torch.no_grad():\n","    outputs = model(images)\n","\n","for idx in range(len(images)):\n","    img_tensor = images[idx].cpu()\n","    pred       = outputs[idx]\n","    boxes      = pred[\"boxes\"].cpu()\n","    labels     = pred[\"labels\"].cpu()\n","    scores     = pred[\"scores\"].cpu()\n","\n","    # ── 1) 점수(threshold) 필터 ──\n","    conf_keep = scores >= 0.3\n","    boxes, labels, scores = boxes[conf_keep], labels[conf_keep], scores[conf_keep]\n","\n","    # ── 2) NMS 적용 ──\n","    if boxes.numel() > 0:\n","        nms_keep = nms(boxes, scores, iou_threshold=0.5)\n","        boxes, labels, scores = boxes[nms_keep], labels[nms_keep], scores[nms_keep]\n","\n","    # ── 3) 시각화 ──\n","    texts = [f\"{category_names[int(l)]}: {s:.2f}\" for l, s in zip(labels, scores)]\n","    img_uint8 = (img_tensor * 255).to(torch.uint8)\n","    vis = draw_bounding_boxes(img_uint8, boxes, labels=texts, colors=\"red\", width=2)\n","\n","    plt.figure(figsize=(6, 6))\n","    plt.imshow(to_pil_image(vis))\n","    plt.axis(\"off\")\n","    plt.title(f\"Sample {idx+1}\")\n","    plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"15PsBBj_5yk9loMsLDM9IElqfqsSXb39W"},"id":"6_VE24RRWTOl","executionInfo":{"status":"ok","timestamp":1752062576468,"user_tz":-540,"elapsed":987,"user":{"displayName":"Junseop So (쏘주형)","userId":"07758510494740838877"}},"outputId":"b26603c9-ad0e-4b0a-acdd-35c227a10079"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"S4ZGZMaCW_L3"},"execution_count":null,"outputs":[]}]}